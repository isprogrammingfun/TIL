## 마이크로벤치마킹과 통계

JVM은 워낙 자유분방한 특성 탓에 성능 수치를 다루기가 의외로 어렵다. 

작은 자바 코드 한 조각의 성능을 정확히 측정(마이크로벤치마킹) 하기란 매우 미묘하고 어려운 일이다. 

갖은 위험을 무릅쓰고라도 애플리케이션 및 유스케이스를 상대로 마이크로벤치마킹을 해야 한다면, 가장 미덥고 진보된 툴로 시작해서 잘 알려진 함정들과 ‘베어 트랩’을 피해 가는 게 좋다. 

JVM은 조심해서 다루어야 할 성능 수치를 계속 낸다. 마이크로벤치마킹 산출 수치는 대부분 매우 민감하므로 성능 엔지니어는 반드시 측정 결과를 통계적으로 정교하게 처리해야 한다. 

### 자바 성능 측정 기초

벤치마크로 공정한 테스트를 하려면 가급적 시스템의 어느 한 곳만 변경하고 다른 외부 요인은 벤치마크 안에 두고 통제하는것이 좋다. 

과학적으로 순수하게 공정한 테스트는 현실적으로 어려운 일이지만, 벤치마크는 경험 결과의 근간을 형성하므로 최소한 반복은 할 수 있어야 한다. 

자바 플랫폼을 벤치마크할 때에는 자바 런타임의 정교함이 가장 문제이다. 최적화의 맥락에서 벤치마크를 과학적인 테스트로 바라보면 우리가 가진 선택지는 제한적이기 때문에 최적화가 미치는 영향을 구체적으로 완전히 이해하고 설명하기란 사실 불가능하다.

다시 말해, 자바 코드 실행은 JIT 컴파일러, 메모리 관리, 그밖의 자바 런타임이 제공하는 서브 시스템과 완전히 떼어놓고 생각할 수 없다. 테스트 실행 당시 OS, 하드웨어, 런타임 조건의 작용 또한 무시할 수 없다. 

이와 같은 여러 가지 작용은 보다 큰 단위(전체 시스템이나 서브시스템)로 처리하여 상쇄시킬 수 있으나 반대로 작은 규모로 마이크로벤치마크를 할 때는 물밑에서 작동하는 런타임과 애플리케이션 코드를 확실히 떼어놓기가 참 어렵다. 

**벤치마크를 하는 과정에서 유의해야 할 점** 

1. JVM 웜업 
    - JIT 컴파일러는 코드를 조금이라도 효율적으로 작동시키기 위해 호츌 계층을 최적화하므로 벤치마크 성능은 캡처 타이밍에 따라 달라진다. 그렇기 때문에 타이밍을 캡처하기 전에 JVM이 가동 준비를 마칠 수 있게 웜업 기간을 두는 게 좋다. 보통 타이밍 세부를 캡처하지 않은 상태로 벤치마크 대상 코드를 여러 번 반복 실행하는 식으로 JVM을 예열시킨다.
2. 가비지 수집(GC)
    - 가비지 수집은 원래 불확정적이기 때문에 직접 설정하기 어렵다.
    - GC가 일어날 가능성이 큰 시기에 타이밍을 캡처하지 않는 것이 그나마 최선이다.
3. 테스트하려는 코드에서 생성된 결과를 실제로 사용하지 않는 실수
    - 죽은 코드는 JIT 컴파일러가 이를 죽은 코드 경로로 식별하고 정작 우리가 벤치마크하려던 것을 최적화해버릴 가능성이 있다.
4. 허용오차
    - 한번 측정한 결과로는 평균을 내도 벤치마크가 어떻게 수행됐는지 전체 사정을 알 수 없다. 허용 오차를 구해 수집한 값의 신뢰도를 파악해야 한다.
    - 허용 오차가 큰 것은 통제불능 변수가 있다는 뜻이거나, 개발된 코드 자체가 성능 기준에 미치지 못함을 의미한다. 어느 쪽이든 허용 오차를 구하지 않고선 문제의 존재조차 알 수 없다.
5. 코드 복잡도, 하드웨어
    - 코드 복잡도가 높아지면 벤치마크는 더 까다로워진다.
    - 동시 코드를 벤치마크할 때는 하드웨어 설정치를 가볍게 웃돌 가능성도 있어서 하드웨어 역시 잘 살펴야 한다.

**해결방안**

1. 시스템 전체를 벤치마크한다. 저수준 수치는 수집하지 않거나 그냥 무시한다.
2. 연관된 저수준의 결과를 의미있게 비교하기 위해 앞서 언급한 많은 문제를 공통 프레임워크를 이용해 처리한다.

## JMH 소개

### 될 수 있으면 마이크로벤치마크하지 말지어다

개발자는 큰 그림을 못 보고 자기 코드가 성능을 떨어뜨렸을 거란 강박 관념에 사로잡힌다. 

작은 코드를 세세히 뜯어보며 원인을 찾으려는 수준으로 벤치마킹하는 건 몹시 어려울 뿐만 아니라 ‘베어 트랩’에 빠질 위험도 있다. 

### 휴리스틱: 마이크로벤치마킹은 언제 하나?

일반적으로 저수준 분석이나 마이크로벤치마킹을 하는 주요 유스케이스

1. 사용 범위가 넓은 범용 라이브러리 코드를 개발한다.
2. OpenJDK 또는 다른 자바 플랫폼 구현체를 개발한다.
3. 지연에 극도로 민감한 코드를 개발한다. 

일반적으로 마이크로벤치마크는 가장 극단적인 애플리케이션에 한하여 사용하는 게 좋다. 

1. 총 코드 경로 실행 시간은 적어도 1밀리초, 실제로는 100마이크로초 보다 짧아야 한다.
2. 메모리 할당률을 측정하는데, 그 값은 1MB/s 미만, 가급적 0에 가까운 값이어야 한다.
3. 100%에 가깝게 CPU를 사용하며 시스템 이용률은 낮게(10% 밑으로)유지해야 한다.
4. 실행 프로파일러로 CPU를 소비하는 메서드들의 분포를 이해해야 한다. 분포 그래프에서 지배적인 영향을 끼치는 메서드는 많아야 두세 개 정도다. 

### JMH 프레임워크

JMH는 자바를 비롯해 JVM을 타깃으로 하는 언어로 작성된 나노/마이크로/밀리/매크로 벤치마크를 제작,실행,분석하는 자바 도구이다. 

JMH는 벤치마크 툴에 관한 다음과 같은 몇 가지 핵심적인 설계 이슈를 고려했다.

1. 벤치마크 프레임워크는 컴파일 타임에 벤치마크 내용을 알 수 없으므로 동적이어야 한다. 리플렉션을 써서 작성한 벤치마크를 실행하는 우회 방법도 있지만, 벤치마크 실행 경로에 복잡한 JVM 서브시스템이 하나 더 끼어들게 되기 때문에 JMH는 벤치마크 코드에 애너테이션을 붙여 자바 소스를 추가 생성하는 식으로 작동한다. 
2. 벤치마크 프레임워크가 유저 코드를 반복 호출할 경우 루프 최적화를 수행하는 문제가 있는데, JMH는 벤치마크 코드가 루프 최적화에 걸리지 않을 정도로 반복 횟수룰 설정한 루프 안에 감싸 넣는다. 

### 벤치마크 실행

JMH 설정 태스크를 마친 후 실행시킬 벤치마크 메서드에는 @Benchmark를 붙인다

벤치마크 실행을 설정하는 매개변수는 명령줄에 넣거나, main() 메서드에 세팅한다.

JMH 프레임워크는 상태를 제어하는 기능까지 제공한다. @State는 상태를 정의하는 애너테이션으로, Benchmark, Group, Thread 세 상태가 정의된 Scope 이늄을 받는다. @State를 붙인 객체는 벤치마크 도중에 액세스할 수 있으므로 어떤 설정을 하는 용도로 쓸 수 있다. 

JMH은 벤치마크에 영향을 줄 수 있는 최적화로부터 보호하기 위해 블랙홀을 사용한다. 블랙홀은 다음과 같은 역할을 한다.

1. 런타임에 죽은 코드를 제거하는 최적화를 못 하게 한다. 
    - 일반적으로 JVM은 메서드 내에서 실행된 코드가 부수 효과를 전혀 일으키지 않고 그 결과를 사용하지 않을 경우 해당 메서드를 삭제 대상으로 삼는다. JMH는 이를 막기 위해 벤치마크 메서드가 반환한 단일 결괏값을 암묵적으로 블랙홀에 할당한다.
2. 반복되는 계산을 상수 폴딩 하지 않게 만든다.
3. 값을 읽거나 쓰는 행위가 현재 캐시 라인에 영향을 끼치는 잘못된 공유 현상을 방지한다.
4. 쓰기 장벽으로부터 보호한다.
    - 성능 분야에서 장벽이란, 일반적으로 리소스가 포화돼서 사실상 애플리케이션에 병목을 초래하는 지점을 가리킨다. 쓰기 장벽에 이르면 캐시에 영향을 미치고 쓰기 전용 버퍼가 오염 될 수 있다.

## JVM 성능 통계

성능 분석은 진정한 실험과학이므로 결과 데이터 분포를 다루는 일은 필수이다.

모든 측정은 어느 정도의 오차를 수반한다. 자바 개발자가 성능 분석 시 흔히 맞닥뜨리는 두 가지 주요 오차 유형이 있다. 

### 오차 유형

- 랜덤 오차 (random error)
    - 측정 오차 또는 무관계 요인이 어떤 상관관계 없이 결과에 영향을 미친다.
    - 이를 나타내는 단어는 정밀도이다. 정밀도가 높으면 랜덤 오차가 낮다.
    - 랜덤 오차는 원인을 알 수 없는, 또는 예기치 못한 운영 환경상의 변화 때문에 일어난다.
    - 랜덤 오차는 대부분 정규 분포를 따른다. 정규 분포는 오차가 측정값에 미치는 긍정적/부정적 영향도가 얼추 비슷한 경우에는 적합하지만 JVM에는 이 모델이 잘 맞지 않는다.
- 계통 오차(systematic error)
    - 원인을 알 수 없는 요인이 상관관계가 있는 형태로 측정에 영향을 미친다.
    - 이를 나타내는 단어는 정확도이다. 정확도가 높으면 계통 오차가 낮다.
    - 계통 오차가 문제인 사례로 성능 테스트를 하는 상황을 예로 들어봤을 때, 테스트 대상 서버는 영국 런던에 있는데 부하 테스트는 인도에서 하는 경우 더 이상 줄일 수 없는 왕복 네트워크 지연 시간이 응답 시간에 포함된 결과 api가 대부분 180 밀리초 안팎의 일정한 응답 시간을 보여준다. 실제로 서비스가 반응한 시간은 120 밀리초에 훨씬 못 미치므로 계통 효과가 커서 실제 응답 시간의 차이가 묻혀버렸다.
- 허위 상관
    - 두 변수가 비슷하게 움직인다고 해서 이들 사이에 연결고리가 있다고 볼 수는 없다.
    - JVM과 성능 분석 영역에서는 그럴싸해 보이는 연결고리와 상관관계만 보고 측정값 간의 인과 관계를 넘겨짚지 않도록 조심해야 한다.

### 비정규 통계학

정규 분포 기반의 통계학에서는 정교한 고급 수학이 별로 필요가 없다. 

학생들은 평균과 표준편차, 그리고 조금 더 수준 높은 왜도, 첨도 같은 내용을 배우지만, 이런 분석 기법은 분포 그래프에 멀찍이 동떨어진 특이점이 몇 개만 있어도 결과가 왜곡되기 쉬운 심각한 단점이 있다.

그렇기에 다른 관점에서 한번 생각을 해보아야 한다. 만약 이미 고객 상당수가 불만을 제기하는 상황이 아니라면, 평균 응답 시간 단축이 목표가 될 일이 거의 없다. 즉, 만족스러운 서비스를 받고 있는 대다수 고객의 경험보다 특이점을 유발하는 이벤트가 더 중요한 관심사이다. 

메서드(또는 트랜잭션) 시간 분포를 좀 더 현실적으로 나타낸 그래프는 정규 분포와는 거리가 먼 긴 꼬리형 비정규 분포의 형태를 가지고 있다. 이 분포 형태는 모든 관련 코드가 이미 JIT 컴파일돼서 GC 사이클이 없는 핫 패스의 존재를 시사한다. 이는 드문 사례는 아니지만 최상의 시나리오로서, 이보다 더 빠른 호출은 있을 수 없다. 

자바 성능 튜닝 중 측정한 값은 대부분 통계적으로 심한 비정규 분포를 나타낸다. 그래서 데이터 형상을 시각화하여 파악하고 싶을 때 HdrHistogram을 이용하면 유용하다. 

## 통계치 해석

웹 애플리케이션 응답은 아주 일반적인 유형의 서버 응답으로, 응답 유형마다 응답 시간 분포는 다르다. 

클라이언트 오류

![120488136-7ad13e00-c3f1-11eb-902d-cc8024428c8a](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/a54a4305-4f6a-49d5-8973-50bce9d018cf)

매핑되지 않은 URL을 클라이언트가 요청하면 웹 서버는 클라이언트 에러를 준다

서버에러

![120488182-83c20f80-c3f1-11eb-83fc-c08e315563ff](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/900a9b21-a9fb-4336-8a94-2ac6aa4a0bc3)


서버에러는 장시간 처리하다가 (백엔드 리소스가 장시간 부하를 받거나 타임아웃에 걸리는 경우 같은) 발생하는 편이다. 

성공 요청

![120488239-8e7ca480-c3f1-11eb-8861-73da30bc006e](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/1bab8a98-d0ee-4613-b243-de9248762dd1)

성공한 요청은 긴 꼬리형 분포를 보이지만, 실제로는 극댓값이 여럿인 다봉분포를 나타낸다. 

전체적인 응답 분포

![120488409-b66c0800-c3f1-11eb-9783-cf5af1785a2f](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/45c132e9-517a-4e78-a872-670932656bbf)

이처럼 일반적인 측정값을 보다 유의미한 하위 구성 요소들로 분해하는 개념은 아주 유용하다. 

분석자는 결괏값을 보고 결혼을 도출하기 전에 먼저 본인이 데이터 및 도메인을 충분히 이해해야 한다. 

데이터를 더 작은 집합으로 쪼개야 할 경우도 있다. 예를 들어 같은 성공 요청이라도 업데이트, 업로드를 하는 요청과 읽기 작업이 대부분인 요청은 전혀 다른 분포를 보일 것이다.

### 추가 공부한 자료
https://ysjee141.github.io/blog/quality/java-benchmark/ <br/>
https://mong9data.tistory.com/131
