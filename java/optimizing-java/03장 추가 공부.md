## 캐시

- 참고 자료: https://parksb.github.io/article/29.html

캐시는 CPU 칩 안에 들어가는 작고 빠른 메모리로, 메인메모리에 저장된 내용 중, 자주 사용하는 데이터를 임시로 저장해두는 기억장치로 저장 공간이 작고 비용이 비싼 대신 빠른 성능을 제공한다. 

자주 사용하는 데이터에 관한 판단은 지역성의 원리를 따르며, 지역성 원리는 시간 지역성(Temporal locality)과 공간 지역성(Spatial locality)으로 구분해서 볼 수 있다.

시간 지역성은 최근 접근한 데이터에 다시 접근하는 경향을 말한다.  예를 들어 루프에서 인덱스 역할을 하는 변수 `i`에는 짧은 시간안에 여러 번 접근이 이뤄진다.

```
for (i = 0; i < 10; i += 1) {
  arr[i] = i;
}
```

공간 지역성은 최근 접근한 데이터의 주변 공간에 다시 접근하는 경향을 말한다. 위 루프의 경우 배열 `arr`의 각 요소를 참조하면서 가까운 메모리 공간에 연속적으로 접근하고 있다. 배열의 요소들이 메모리 공간에 연속적으로 할당되기 때문이다.

프로세스 실행 중 접근한 데이터의 접근 시점을 X축으로, 메모리 주소를 Y축으로 그래프를 표시해보면, 시간 지역성은 — 형태로 데이터가 분포되어 있고, 공간 지역성은 | 형태로 분포 되어있다. 

CPU 칩에는 여러 개의 캐시가 들어가며, 각각의 캐시는 각자의 목적과 역할을 가지고 있다.

```
+-------------+------+------+     +---------------+     +--------+
|             |  I$  |      | <-- |               | <-- |        |
+  Processor  +------+  L2  |     |  Main Memory  |     |  Disk  |
|             |  D$  |      | --> |               | --> |        |
+-------------+------+------+     +---------------+     +--------+

```

- L1 Cache: 프로세서와 가장 가까운 캐시. 속도를 위해 I$와 D$로 나뉜다. 빠르지만 용량이 제한적이다.
    - Instruction Cache (I$): 메모리의 TEXT 영역 데이터를 다루는 캐시.
        - 메모리의 TEXT 영역 데이터는 프로그램의 실행 코드(Instructions)를 저장하는 영역이다. TEXT 영역은 읽기 전용(Read-Only)으로 지정되어 있으며, 프로그램이 실행될 때 CPU가 해당 영역의 명령어들을 가져와 실행한다.
    - Data Cache (D$): TEXT 영역을 제외한 모든 데이터를 다루는 캐시.
        - TEXT 영역을 제외한 데이터에는 무엇이 있을까?
            1. 데이터(Data) 영역:
            데이터 영역은 프로그램이 실행되는 동안 사용되는 전역 변수, 정적 변수, 배열, 구조체 등의 데이터를 저장하는 영역이다. 프로그램이 실행되면서 이 영역의 데이터들이 변경될 수 있다.
            2. 스택(Stack) 영역:
            스택 영역은 함수의 호출과 관련된 지역 변수, 매개변수, 함수의 복귀 주소 등을 저장하는 영역이다. 함수가 호출될 때마다 스택 프레임(Stack Frame)이 생성되며, 함수의 실행이 끝나면 해당 스택 프레임이 제거된다.
            3. 힙(Heap) 영역:
            힙 영역은 프로그램이 실행 중에 동적으로 할당되는 데이터를 저장하는 영역이다. 프로그래머가 메모리를 동적으로 할당하고 해제할 수 있는 영역으로, 주로 동적으로 크기가 변하는 데이터 구조(예: 동적 배열, 연결 리스트 등)에 사용된다.
    - 예를 들어, 다음과 같은 코드가 있다.
        
        ```c
        #include <stdio.h>
        
        int main() {
        int a = 10;
        int b = 20;
        int sum = a + b;
        printf("Sum: %d\n", sum);
        return 0;
        }
        ```
        
        이때 Instruction Cache에는 **`main`** 함수와 **`printf`** 함수의 실행에 필요한 명령어가 들어가고, Data Cache에는 **`a`**, **`b`**, **`sum`**과 같은 변수들의 값이 들어간다. 
        
- L2 Cache: 용량이 큰 캐시. 크기를 위해 L1 캐시처럼 나누지 않는다. 속도는 느리지만 용량이 크기 때문에 더 많은 데이터를 저장할 수 있다.
- L3 Cache: 멀티 코어 시스템에서 여러 코어가 공유하는 캐시. 속도는 느리지만 용량이 크기 때문에 더 많은 데이터를 저장할 수 있다.
- 캐시는 캐시 라인(Cache Line)이라는 작은 데이터 블록 단위로 데이터를 저장한다. 캐시 라인에는 메모리에서 가져온 데이터와 해당 데이터의 주소(Tag) 정보가 포함된다. CPU가 데이터에 접근할 때, 먼저 캐시에 해당 데이터가 있는지 검사하고, 있으면 캐시로부터 데이터를 가져오고, 없으면 메모리로부터 데이터를 가져와 캐시에 저장한다. 캐시의 효율성은 CPU가 자주 사용하는 데이터를 적절하게 캐시에 저장해야 하므로, LRU(Least Recently Used) 같은 캐시 교체 알고리즘이 사용되어 오래된 데이터를 새로운 데이터로 교체한다. 이렇게 함으로써 CPU가 빠르게 원활한 작업을 수행할 수 있도록 도와준다.

## 동시 기록, 후기록

- 참고 자료 : https://cyber0946.tistory.com/81

![다운로드](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/a9b63d45-6775-49b3-9b59-dbd1ddd82fda)

캐시는 읽기 위해 사용되고, 쓰기 명령을 수행할 때도 사용된다. 위에 그림처럼 write buffer와 함께 사용해 쓰기 성능을 높인다. 쓰기 버퍼 방식은 크게 두 가지가 존재한다. Write Through와 Write Back이다.

### 동시 기록 (write-through)

CPU가 데이터를 사용하면 캐시에 저장되게 되는데, 데이터가 캐시 됨과 동시에 주기억장치 또는 디스크로 기입되는 방식을 지원하는 구조의 캐시이다. 즉, 캐시와 메모리 둘다에 업데이트를 해버리는 방식이다.

장점 : 캐시와 메모리에 업데이트를 같이 하여, 데이터 일관성을 유지할 수 있어서 안정적이다.
단점 : 속도가 느린 주기억장치 또는 보조기억장치에 데이터를 기록할 때, CPU가 대기하는 시간이 필요하기 때문에 성능이 떨어진다.

데이터 로스가 발생하면 안되는 상황에서는 Write Through를 사용하는 것이 좋다.

### 후기록 (write-back)

CPU 데이터를 사용할 때 데이터는 먼저 캐시로 기록되는데, 캐시 내에 일시적으로 저장된 후에 블록 단위에 캐시로부터 해제되는 때(캐시안에 있는 내용을 버릴시) 에만 주기억장치 또는 보조기억장치에 기록되는 방식이다. 즉, 데이터를 쓸 때 메모리에는 쓰지 않고 캐시에만 업데이트를 하다가 필요할 때에만 주기억장치나 보조기억장치에 기록하는 방법이다.

장점 : Write Through보다 훨씬 빠르다.
단점 : 속도가 빠르지만 캐시에 업데이트 하고 메모리에는 바로 업데이트를 하지 않기 때문에, 캐시와 메모리가 서로 값이 다른 경우가 발생할 때가 있다.
빠른 서비스를 요하는 상황에서는 Write Back을 사용하는 것이 좋다.

## TLB

- 참고 자료 : https://wpaud16.tistory.com/304

먼저, 페이지 테이블이 뭔지 부터 알아야 한다. 페이지 테이블이란 가상 주소와 실제 주소를 매핑하는 테이블이다. CPU가 가상 주소를 생성하면 이 가상 주소가 실제 주소로 어떻게 변환되어야 하는지 정보를 가지고 있다. 즉 페이지 테이블은 실제 주소를 가지고 있다. 이는 메인 메모리에 존재하며 프로세스마다 고유의 페이지 테이블을 가진다. context switching 할 때마다 페이지 테이블도 변경돼야 한다. 즉, CPU가 어느 페이지 테이블을 사용할지 알아야 한다. 

페이지 테이블이 메인 메모리에 존재하기 때문에 CPU는 메인 메모리에 최소 2번은 접근해야 원하는 데이터를 얻을 수 있다. 

1. page table에 한번 접근 (Fetch)
2. page table을 기반으로 실제 메모리로 접근 (Memory access)

이렇게 되면 명령어 하나하나 실행할 때마다 같은 table이지만 메인 메모리에 접근해야 하는 불필요한 일이 발생한다. 이런 이런 메모리의 접근을 줄이고자 나온 게 TLB ( Translation Look-aside Buffer )다. 하드웨어적으로 지원하여 page table의 임시저장 cache 역할을 한다. 메모리에 접근하는 건 너무 느리기 때문이다. TLB는 최근에 읽었던 page table entry(변환될 물리 주소)를 매핑하여 저장하는데, TLB에 있으면 메모리에 접근하기 전에 막아야 하기 때문에 크기를 작게 하여 속도를 높였다(64 ~ 1024 entry). TLB 동작 방식은 아래와 같다.

![다운로드 (3)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/4da07797-7067-42c6-9b6c-75d9d498d1ca)


CPU에서 나온 정보를 가지고 TLB를 탐색하고, 있다면 바로 물리 주소에 접근하고, 없다면 page table로 들어간다.

TLB에 page table entry의 정보가 없을 땐 TLB miss라고 하는데 2가지 종류가 있다.

1. TLB miss

2. Page Fault

기본 TLB miss는 TLB엔 없지만 main memory에는 올라가 있는 상태를 의미한다. 그러니 page table을 가져와서 TLB에 저장하면 간단히 해결된다. 10 cycle정도면 TLB에 정보를 저장할 수 있다. 하드웨어나 소프트웨어의 통제를 받는데 하나의 exception이라고 보면 된다.

하지만 Page Fault는 다르다. 요청한 page가 main memory에 없는 상태를 의미한다.

그러니 hard disk에서부터 불러와야 한다. 그러니 약 1,000,000 cycle정도 소요해야 TLB에 정보를 저장할 수 있다. 엄청난 차이가 있는데 이러니 page Fault를 최대한 발생시키지 않아야 한다.

## JMM

- 참고 자료 : https://aroundck.tistory.com/3422, https://parkcheolu.tistory.com/14

제대로 작동하는 컨커런트 프로그램을 구상할 때 자바 메모리 모델을 이해하는 일은 매우 중요하다. 자바 메모리 모델은 어떻게, 그리고 언제 쓰레드들이 공유 변수의 값을 볼 수 있는지 명시한다. 그리고, 공유 변수로의 접근을 어떻게 동기화하는지 알려준다.

JMM 은 변수에 저장된 값이 어느 시점부터 다른 스레드의 가시권에 들어가는지에 대해 JVM 이 해야만 하는 최소한의 보장만 할 뿐이다.

JMM 은 예측성에 대한 필요와 함께 높은 성능의 JVM 을 다양한 종류의 프로세서 구조에서 동작하도록 해야 한다는 실제적인 요구 사항을 쉽게 구현할 수 있어야 한다는 점의 균형을 맞출 목적으로 설계됐다.

특히 JMM 의 일부는 JVM 에서 실행되는 프로그램의 성능을 최대한 끌어낼 수 있도록 최신 프로세서와 컴파일러에서 사용하는 여러 기법을 사용하고 있다.

## 락, volatile

- 참고 자료: https://parkcheolu.tistory.com/24, https://junghyungil.tistory.com/99

락은 synchrnonized 블록과 유사한 쓰레드 동기화 메카니즘이다. 락은 synchronized 블록보다 더 정교하고 세련된 방식의 동기화를 가능하게 한다. 락은 synchronized 블록을 이용해 구현되며, 때문에 락을 사용한다고 해서 synchronized 블록이 완전히 사라지는 것은 아니다.

Java 5 부터 추가된 java.util.concurrent.locks 패키지는 몇 가지 락 구현을 포함하고 있기 때문에 락을 스스로 구현할 필요는 없어졌다.

volatile 키워드는 java 변수를 Main Memory에 저장하겠다 라는것은 명시하는 키워드이다. 즉, 모든 volatile 변수는 컴퓨터의 메인 메모리로부터 읽히고, volatile 변수에 대한 쓰기 작업은 메인 메모리로 직접 이루어진다. CPU 캐시가 쓰이지 않는다는 말이다. 

non-volatile일 때의 문제점

![다운로드 (6)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/72645d93-c737-45f0-8bbd-6a5d34e3daf4)

멀티쓰레드 어플리케이션에서의 non-volatile 변수에 대한 작업은 성능상의 이유로 CPU 캐시를 이용한다. 둘 이상의 CPU가 탑제된 컴퓨터에서 어플리케이션을 실행한다면, 각 쓰레드는 변수를 각 CPU의 캐시로 복사하여 읽어들인다.

non-volatile 변수에 대한 작업은 JVM 이 메인 메모리로부터 CPU 캐시로 변수를 읽어들이거나, CPU 캐시로부터 메인 메모리에 데이터를 쓰거나 할 때에 대한 어떠한 보장도 하지 않는다.

- volatile 변수를 사용하고 있지 않는 MultiThread 어플리케이션에서는 Task를 수행하는 동안 성능 향상을 위해 Main Memory에서 읽은 변수 값을 CPU Cache에 저장하게 된다.
- 만약에 Multi Thread환경에서 Thread가 변수 값을 읽어올 때 각각의 CPU Cache에 저장된 값이 다르다면, 변수 값 불일치 문제가 발생하게 된다.

변수 값 불일치 문제는 언제 발생하게 될까? 다음 예시가 있다.

```
public class SharedObject {
		public int counter = 0;
}
```

둘 이상의 쓰레드가 다음과 같은 공유 객체로 접근하는 경우를 생각해보자.

![221C873956FA88EA2B](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/a3af58b7-128f-41a5-817b-5189ea71a5d8)

Thread1 은 counter 변수를 증가시키고, Thread1 과 Thread2 가 때에 따라서 counter 변수를 읽는다.

만일 counter 변수에 volatile 키워드가 없다면, counter 변수가 언제 CPU 캐시에서 메인 메모리로 쓰일지(written) 보장할 수 없다. CPU 캐시의 counter 변수와 메인 메모리의 counter 변수가 다른 값을 가질 수 있다는 것이다.

쓰레드가 변경한 값이 메인 메모리에 저장되지 않아서 다른 쓰레드가 이 값을 볼 수 없는 상황을 '가시성' 문제라 한다. 즉, 한 쓰레드의 변경(update)이 다른 쓰레드에게 보이지 않는다. 이 문제는 volatile 키워드가 해결해준다. counter 변수에 volatile 키워드를 선언한다면 이 변수에 대한 쓰기 작업은 즉각 메인 메모리로 이루어질 것이고, 읽기 작업 또한 메인 메모리로부터 다이렉트로 이루어질 것이다.

## 컨텍스트 교환

- 참고 자료: https://yoongrammer.tistory.com/52, https://spurdev.tistory.com/13, [https://velog.io/@curiosity806/Context-Switching으로-알아보는-process와-thread#3-context-switching](https://velog.io/@curiosity806/Context-Switching%EC%9C%BC%EB%A1%9C-%EC%95%8C%EC%95%84%EB%B3%B4%EB%8A%94-process%EC%99%80-thread#3-context-switching)

CPU가 현재 작업 중인 프로세스에서 다른 프로세스로 넘어갈 때 지금까지의 프로세스의 상태를 저장하고, 새 프로세스의 저장된 상태를 다시 적재하는 작업을 Context Switch(문맥 교환)이라 한다. Context Switching하는 동안 CPU는 아무일도 하지않는 시간이 발생하는데, 이를 오버헤드(Overhead)라 하고 오버헤드가 잦아지면 성능이 떨어질 수 있다.

### 컨텍스트

프로그래밍에서 Context는 (동작, 작업들의 집합)을 (정의, 관리, 실행)하도록 하는 (최소한의 상태, 재료, 속성)을 포함하는 (객체, 구조체, 정보)이다.

Process의 경우 현재 프로세스가 중단 되었을 때, 중단된 시점 부터 다시 프로세스를 실행하기 위한 정보를 Context라고 부른다. 이러한 Process의 Context 정보는 PCB(Proccess Control Block)이라는 구조체에 저장된다. 

### PCB

운영체제가 프로세스를 제어하기 위해 정보를 저장해 놓는 곳으로, 프로세스의 상태 정보를 저장하는 자료구조이다. 운영체제에서 프로세스는 PCB로 표현된다

운영체제에 따라 PCB에 포함되는 항목이 다를 수 있지만, 일반적으로 다음과 같은 정보가 포함되어 있다.

![다운로드 (7)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/5b1a55aa-6529-4731-bf28-8ebd25008061)

- **포인터**
    
    프로세스의 현재 위치를 저장하는 포인터 정보
    
- **프로세스 상태**
    
    프로세스의 각 상태 (생성(New), 준비(Ready), 실행(Running), 대기(Waiting), 종료(Terminated))
    
- **프로세스 번호**
    
    프로세스 식별자를 저장하는 프로세스 ID 또는 PID라는 고유 한 ID
    
- **프로그램 카운터**
    
    프로세스를 위해 실행될 다음 명령어의 주소를 포함하는 카운터
    
- **레지스터**
    
    누산기, 베이스, 레지스터 및 범용 레지스터를 포함하는 CPU 레지스터에 있는 정보
    
- **메모리 제한**
    
    운영 체제에서 사용하는 메모리 관리 시스템에 대한 정보. 여기에는 페이지 테이블, 세그먼트 테이블 등이 포함될 수 있다.
    
- **열린 파일 목록**
    
    프로세스를 위해 열린 파일 목록
    
    운영체제는 빠르게 PCB에 접근하기 위해 `프로세스 테이블`을 사용하여 각 프로세스의 PCB를 관리한다.
    
    ### 언제 발생하는가?
    
    - 멀티태스킹(Multitasking)
        - 실행 가능한 프로세스들이 운영체제의 스케줄러에 의해 조금씩 번갈아가며 수행되는 것을 말한다.
        - 번갈아 가며 프로세스가 CPU를 할당 받는데 이때 Context Switching 한다.
        - 사용자가 체감하기 힘든 속도로 Context Switching되며 프로세스가 처리되기 때문에 동시에 처리되는 것처럼 느껴진다.
    - 인터럽트 핸들링(Interrupt handling)
        - 인터럽트란 컴퓨터 시스템에서 예외 상황이 발생했을때 CPU에게 알려 처리할 수 있도록 하는 것을 말한다.
        - 인터럽트가 발생하면 Context Switching한다.
        - I/O request : 입출력 요청
        - time slice expired : CPU 사용시간이 만료
        - fork a child : 자식 프로세스 생성
        - wait for an interrupt : 인터럽트 처리 대기
    - 사용자와 커널 모드 전환(User and kernel mode switching)
        - 사용자와 커널 모드 전환은 Context Switch가 필수는 아니지만 운영체제에 따라 발생할수 있다
        - 커널 모드, 사용자 모드? (참고 자료: https://kosaf04pyh.tistory.com/196)
            - 하드웨어 적인 보안을 유지하기 위해 운영체제는 기본적으로 두가지 모드를 제공하는데 커널모드(kernel mode, system mode), 사용자 모드(user mode)가 이에 해당한다.
            - 커널 모드는 운영체제가 CPU의 제어권을 가지고 운영 체제 코드를 실행하는 모드로서, 이 모드에서는 모든 종류의 명령을 다 실행할 수 있다. 반면에 사용자 모드에서는 일반 사용자 프로그램이 실행되며 제한적인 명령만을 수행할 수 있다. 시스템에 중요한 영향을 미치는 연산은 커널 모드에서만 실행 가능하도록 함으로써 하드웨어의 보안을 유지하는 것이다.
            - 커널 모드와 사용자 모드를 구분하기 위해 하드웨어 적으로 CPU 내부에 모드 비트(mode bit)를 사용한다. 모드 비트가 0으로 세팅되어 있으면 커널 모드로서 모든 명령을 수행할 수 있고, 모드 비트가 1로 세팅되어 있으면 사용자 모드로서 제한된 명령만을 수행할 수 있다.

### 교환 과정

![다운로드 (8)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/c721b578-5551-452c-aa8d-a8fc901d916c)


1. P0 실행 중 운영체제에서 프로세스의 스케줄러에 의해 인터럽트 발생
2. 프로세스가 실행되는 유저 모드에서 커널 모드로 전환
3. 기존에 실행되었던 현재 프로세스(P0)의 상태/정보를 자신의 PCB0에 저장
4. PCB1로부터 다음에 실행되는 프로세스(P1)의 상태/정보 복구
5. 커널 모드에서 유저 모드로 전환
6. 새로운 프로세스 P1 실행