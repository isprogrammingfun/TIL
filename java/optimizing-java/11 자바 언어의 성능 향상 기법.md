## 자바 언어의 성능 향상 기법

네트워크 연결, I/O, DB 등의 애플리케이션 외부 요인 다음으로 병목을 일으킬 공산이 가장 큰 부분이 코드 설계이다. 설계는 바로 잡기가 매우 어려울뿐더러 완벽한 설계란 있을 수 없다. 

그럼에도 성능에 민감한 개발자는 반드시 마음에 새겨둬야 할 코드의 기본 원칙이 있다. 일례로, 데이터를 애플리케이션에 어떻게 저장할지는 매우 중요한 문제이다. 비즈니스 요건이 달라지면 데이터를 저장하는 방법도 달라질 수밖에 없다. 데이터를 저장할 때 어떤 옵션을 사용 가능할 수 있는지 이해하려면 자바 컬렉션 API가 지원하는 자료 구조 및 구현 세부를 꿰고 있어야 한다.

### 컬렉션 최적화

대부분의 프로그래밍 언어 라이브러리는 최소한 두 가지 컨테이너를 제공한다.

- 순차 컨테이너 : 수치 인덱스로 표기한 특정 위치에 객체를 저장한다.
- 연관 컨테이너 : 객체 자체를 이용해 컬렉션 내부에 저장할 위치를 결정한다.

컨테이너에서 메서드가 정확히 작동하려면 저장할 객체가 호환성과 동등성 개념을 지니고 있어야 한다. 코어 자바 컬렉션 API에서는 모든 객체가 반드시 hashCode() 및 equals() 메서드를 구현해야 한다고 표현한다. 

참조형 필드는 힙에 레퍼런스로 저장된다. 객체가 순차적으로 저장된다고 대충 이야기 하지만, 사실 컨테이너에 저장되는건 객체 자신이 아니라, 객체를 가리키는 레퍼런스이다. 그렇기에 C/C++ 형식의 배열이나 벡터를 사용하는 것 만큼 성능을 얻을 수는 없다.

자바는 메모리 서브시스템이 알아서 가비지 수집을 해주는 대신, 저수준의 메모리 제어를 포기할 수밖에 없다. 메모리 수동 할당/해제는 물론, 저수준 메모리 레이아웃 제어까지 단념해야 한다. 

길 테네는 바로 이것이 자바와 C 사이를 갈라놓는 최후의 주된 성능 장벽이라 주장한다. [ObjectLayout](http://objectlayout.org/) 에는 레이아웃을 표준화할 수 있는 방법과 자바 7 이상에서 컴파일/실행이 가능한 코드가 수록되어 있다. JVM을 최적화하면 다른 JVM과의 호환성을 깨뜨리지 않고도 이런 타입을 받을 수 있고 정확히 본래 의미대로 자료 구조를 배치할 수 있다는 것이다. 

### List 최적화

자바에서는 리스트를 ArrayList와 LinkedList, 두 가지 기본 형태로 나타낸다. 

**ArrayList**

ArrayList는 고정 크기 배열에 기반한 리스트이다. 배킹 배열의 최대 크기만큼 원소를 추가할 수 있고 이 배열이 꽉 차면 더 큰 배열을 새로 할당한 다음 기존 값을 복사한다. 따라서 성능에 민감한 프로그래머는 크기 조정 작업 비용과 유연성을 잘 저울질해야 한다. 

ArrayList는 처음에 빈 배열로 시작하고 처음 원소가 추가될 때 용량 10인 기반 배열을 할당한다. 초기 용량값을 생성자에 전달하면 이렇게 크기 조정을 안 해도 된다. ensureCapacity() 메서드를 이용해 ArrayList 용량을 늘려도 크기 조정 작업을 건너뛸 수 있다.

```java
@Benchmark
public List<String> properlySizedArrayList() {
					List<String> list = new ArrayLust<>(1_000_000);
					for(int i = 0; i < 1_000_000; i++) {
									list.add(item);
					}
					return list;
}

@Benchmark
public List<String> resizingArrayList() {
				List<String> list = new AttayList<>();
				for(int i = 0; i < 1_000_000; i++) {
				list.add(item);
				}
				return list;
}
```

위에 코드를 실행했을 때, properlySizedArrayList 테스트가 원소 추가 작업을 초당 약 100회 더 처리했다. 재할당 비용이 고루 상쇄돼도 전체 비용은 그대로이기 때문이다. 아무래도 ArrayList 크기를 정확히 결정하고 시작하는 게 성능은 더 낫다. 

**LinkedList**

LinkedList는 동적으로 증가하는 리스트이다. 이중 연결 리스트로 구현되어 이어서 리스트에 덧붙이는 작업은 항상 O(1)이다. 원소가 리스트에 더해질 때마다 노드가 생성되고 이 노드를 이전 원소가 바라볼 것이다.

**ArrayList VS LinkedList**

ArrayList, LinkedList 둘 중 어느 것을 사용할지는 데이터 접근/수정 패턴에 따라 다르다. 리스트 끝에 원소를 삽입하는 작업은 둘다 일정한 시간이 소요된다.

그러나 ArrayList의 특정 인덱스에 원소를 추가하려면 다른 원소들을 모두 한 칸씩 우측으로 이동시켜야 한다. 반면 LinkedList는 삽입 지점을 찾기 위해 노드 레퍼런스를 쭉 따라가는 수고는 있지만, 삽입 작업은 노드를 하나 생성한 다음 두 레퍼런스(하나는 리스트 처음에 위치한 노드를 가리키는 first, 다른 하나는 리스트의 다음 노드를 가리키는 next)를 세팅하면 간단히 끝난다. 

원소 삭제도 비슷하다, LinkedList는 많아야 레퍼런스 2개만 바꾸면 되므로 훨씬 저렴하다. ArrayList는 삭제할 원소 오른편에 있는 원소들을 모두 한 칸씩 좌측으로 보내야 한다. 

리스트를 주로 랜덤 랙세스하는 경우라면 ArrayList를 사용하는 게 좋다. 모든 원소를 O(1) 시간 만에 가져올 수 있기 때문이다. LinkedList는 처음부터 인덱스 카운트만큼 원소를 방문해야 한다. LinkedList의 고유 기능이 꼭 필요한 경우가 아니라면, 특히 랜덤 액세스가 필요한 알고리즘을 구사할 때에는 ArrayList를 사용하는 것이 좋다. 그리고 ArrayList는 가급적 미리 크기를 지정해서 중간에 다시 조정하는 일이 없도록 하는 게 좋다. 

### Map 최적화

매핑이란 키와 연관된 값 사이의 관계를 뜻한다. 자바는 java.util.Mapp<K,V> 인터페이스를 제공하며, 키/값 모두 반드시 참조형이어야 한다.

**HashMap**

다음은 HashMap 축소 버전에 들어 있는 핵심 메서드이다.

```java
public Object get(Object key) {
		// 편의상 널 키는 지원하지 않음
		if (key == null) return null;
		
		int hash = key.hashCode();
		int i = indexFor(hash, table.length);
		for (Entry e = table[i]; e != null; e = e.next) {
					Object k;
					if (e.hash == hash && ((k = e.key) 00 key || key.equals(k)))
							return e.value;
		}

		return null;
}

private int indexFor(int h, int length) {
	return h & (length - 1):
}

static class Node implements Map.Entry {
		final int hash;
		final Object key;
		Object value;
		Node next;

		Node(int h, Object k, Object v, Entry n) {
				hash = h;
				key = k;
				value = v;
				next = n;
	}
}
```

여기서 HashMap.Node 클래스는 java.util 패키지에서만 접근할 수 있다. 정적 클래스를 사용하는 전형적인 유스케이스이다. 

처음에 버킷 엔트리를 리스트에 저장한다. 값을 찾으려면 키 해시값을 계산하고 equals() 메서드로 리스트에서 해당 키를 찾는다. 키를 해시하고 동등성을 기준으로 리스트에서 값을 찾는 매커니즘으로 키 중복은 허용되지 않는다. 같은 키를 넣으면 원래 HashMap에 있던 키를 치환한다.

자바 최근 버전에서 한 가지 개전된 점은, 기존 indexFor() 메서드를 키 객체의 hashCode() 메서드를 사용하는 코드로 교체하고, 마스크를 적용해 상위 비트를 아랫쪽 해시 부분에 분산시킨 것이다. 즉, HashMap이 키 해시값을 계산할 때 상위 비트를 무조건 반영하도록 설계한 것이다. 이렇게 하지 않으면 인덱스 계산 시 상위 비트가 누락될 수 있기 때문에 여러 가지로 문제가 된다. 무엇보다 입력 데이터에 미세한 변화가 생겨도 해시 함수의 출력 데이터는 아주 크게 요동칠 수 있다는 셰넌의 엄격한 눈사태 원칙과 배치된다.

HashMap 생성자에 전달하는 initialCapacity와 loadFactor 두 매개변수는 HashMap의 성능에 가장 큰 영향을 미친다. HashMap 용량은 현재 생성된 버킷 개수(디폴트 값 16)를, loadFactor는 버킷 용량을 자동 증가(2배)시키는 한계치이다. 용량을 2배 늘리고 저장된 데이터를 다시 배치한 다음, 해시를 다시 계산하는 과정을 재해시라고 한다.

HashMap의 initialCapacity를 설정하는 것도 ArrayList 경우와 같다. 저장한 데이터 양을 대략이나마 미리 알 수 있다면 그에 따라 설정하는 것이 좋다.

initialCapacity가 정확하면 테이블이 커져도 종 재해시할 일은 없다. loadFactor를 조정해도 되지만 0.75 정도면 공간과 접근 시간의 균형이 대략 맞는다. 0.75 이상이면 재해시 하는 빈도는 줄지만, 전반적으로 버킷이 꽉 차기 시작하고 접근 시간이 느려진다. 최대 원소 개수를 loadFactor로 나눈 값을 initialCapacity로 설정하면 재해시가 발생하지 않는다. 

HashMap의 get(), put() 작업은 일정 시간이 소요되지만 순회를 하면 비용이 증가할 수 있다. 자바 문서에도 나와 있듯이, initialCapacity와 loadFactor를 높게 잡으면 순회 시 성능에 상당한 영향을 받는다. 

트리화도 성능에 영향을 주는 또 다른 요인이다. 이 기술은 비교적 최근에 HashMap 내부에 구현된 기술로, 성능 엔지니어로 유용하게 쓸 수 있다. 버킷이 금세 채워지는 상황을 생각해 보자. 버킷 원소를 LinkedList로 구현하면 원소 하나를 찾으러 리스트를 훑어보는 작업도 크기가 커질수록 평균 비용이 더 든다. 

최신 HashMap에는 새로운 장치가 달려 있어서 이처럼 비용이 크기에 비례하여 늘지 않는다. 하나의 버킷에 TREEIFY_THRESHOLD 에 설정한 개수만큼 키/값 쌍이 모이면 버킷은 TreeNode로 바꿔버린다.  그래서 마치 TreeMap처럼 작동한다. 그렇다고 이를 처음부터 적용하기엔 무리가 있다. TreeNode는 리스트 노드보다 약 2배 더 커서 그만큼 공간을 더 차지한다. 값이 고루 잘 분포되는 해시 함수를 쓰면 사실 버킷을 TreeNode로 바꿀 일이 거의 없다. 만약 그런 일이 벌어질 수밖에 없는 상황이라면 HashMap의 해시 함수, initialCapacity, loadFactor 설정을 다시 한번 검토해보는게 좋다. 

- LinkedHashMap
    - LinkedHashMap은 HashMap의 서브클래스로, 이중 연결 리스트를 사용해 원소의 삽입 순서를 관리한다.
    - LinkedHashMap의 기본 관리 모드는 삽입 순서이지만, 액세스 순서 모드로 바꿀 수 있다. LinkedHashMap은 순서가 중요한 코드에서 많이 쓰이지만, TreeMap 처럼 비용이 많이 들지 않는다.
    - Map을 사용하는 코드에서는 대부분 삽입/접근 순서가 별로 중요하지 않기 때문에 LinkedHashMap을 써야 할 일은 비교적 드문 편이다.

### TreeMap

TreeMap은 레드-블랙 트리를 구현한 Map이다. 레드-블랙 트리는 기본 이진 트리 구조에 메타데이터를 부가해서 트리 균형이 한쪽으로 치우치는 현상을 방지한 트리이다. 

TreeMap은 다양한 키가 필요할 때 아주 유용하며, 서브맵에 신속히 접근할 수 있다. 또 처음부터 어느 지점까지, 또 어느 지점부터 끝까지 데이터를 분할하는 용도로도 쓰인다.

TreeMap이 제공하는 get(), put(), containsKey(), remove() 메서드는 log(n) 작업 성능을 보장한다.

실제로 대부분의 요건은 HashMap만으로도 충분하지만, 스트림이나 람다로 Map 일부를 처리해야 할 때도 있을 것이다. 그런 경우엔 TreeMap처엄 데이터 분할이 주특기인 구현체를 쓰는 편이 좋다.

### MultiMap은 없어요

자바는 MultiMap (하나의 키에 여러 값을 묶은 맵) 구현체를 제공하지 않는다. 공식 문서에 다르면 MultiMap을 쓸 일이 드믈고 대부분 Map<K, List<V>> 형태로도 충분히 구현이 가능하다.

## Set 최적화

자바에는 세 종류 Set이 있고 성능에 관해서 고려해야 할 사항은 Map과 비슷하다. 실제로 HashSet은 HashMap(LinkedHashSet은 LinkedHashMap)으로 구현되어 있다.

```java
public class HashSet<E> extends AbstractSet<E> implements Set<E>, Serializable {
				private transient HashMap<E, Object> map;

	private static final Object PRESENT = new Object();
		
		public HashSet() {
			map = new HashMap<>();
		}
		HashSet(int initialCapacity, float loadFactor, boolean dummy) {
		map = new LinkedHashMap<>(initialCapacity, loadFactor);
	}

	public boolean add(E e) {
			return map.put(e,PRESENT) == null;
	}
}
```

Set은 중복값을 허용하지 않는다. Map의 키 원소와 똑같다. HashSet의 add() 메서드가 내부적으로 사용하는 HashMap은 키가 원소 E, 값이 PRESENT라는 더미 객체로 구성된다. 

PRESENT는 처음 한번 만들어 참조하는 객체라서 오버헤드는 무시할 정도이다. HashSet의 두 번째 protected 생성자는 LinkedHashMap 객체를 받는데, 이로써 삽입 순서를 유지하는 LinkedHashMap 로직을 그대로 따라할 수 있다. HashSet의 삽입/삭제, contains 작업은 복잡도가 O(1)이고 원소 순서는 LinkedHashSet로 사용하지 않는 한 유지하지 않으며, 순회비용은 initialCapacity, loadFactor에 따라 달라진다. 

TreeSet 역시 앞서 배운 TreeMap을 활용한다. TreeSet은 Comparator에 정의한 순서대로 정렬된 키 순서를 유지하므로 TreeSet에 더 알맞게 범위 기반 작업 및 순회 작업을 할 수 있다. TreeSet의 삽입/삭제 복잡도는 log(n)이며 원소 순서는 유지된다. 

### 도메인 객체

도메인 객체는 애플리케이션에 유의미한 비즈니스 컨셉을 나타낸 코드이다. 예를 들어 전자 상거래 시스템이라면 Order, OrderItem, DeliverySchedule 등이 도메인 객체가 될 것이다. 도메인 객체는 대부분 타입 간에 연관되어 있다. 

도메인 객체는 애플리케이션에서 일차적인 비즈니스 관심사를 나타내고 어느 정도 유일한 상태값을 지니고 있기 때문에 메모리 누수 같은 버그를 찾는 과정에서 쉽게 눈에 띈다. 

자바 힙에 관한 기본적인 팩트를 살펴보면 그 이유를 알 수 있다. 

- 가장 흔히 할당되는 자료 구조는 스트링, char 배열, byte 배열, 자바 컬렉션 타입의 인스턴스이다.
- jmap에서 누수되는 데이터는 비정상적으로 비대한 데이터셋으로 나타난다.

즉, 메모리 점유량과 인스턴스 개수 모두 보통 코어 JDK에 있는 자료 구조가 상위권을 형성하는 게 보통이다. 그런데 애플리케이션에 속한 도메인 객체가 jmap 결과치의 상위 20위 정도 안에 든다면 꼭 그렇다고 단정 지을 순 없지만 메모리 누수가 발생한 신호라고 볼 수 있다. 

메모리 누수를 일으키는 도메인 객체의 또 다른 특징은 ‘전체 세대’ 효과이다. 특정 타입의 객체가 응당 수집되어야 할 시점에 수집되지 않을 경우, 결국 여러 차례 수집 사이클을 견뎌내고 별의별 세대 카운트 값을 지닌 채 테뉴어드 세대까지 살아남을 것이다. 

세대 카운트별 바이트 히스토그램을 찍어보면 누수를 일으킬 가능성이 있는 도메인 객체가 전체 세대에 걸쳐 분포한다. 인위적으로 자연 수명을 훨씬 뛰어넘어 살아남았기 때문이다.

신속하게 대처하려면 일단 도메인 객체에 대응되는 데이터셋의 크기를 살피고 그 수치가 온당한지, 그리고 작업 세트에 존재하는 도메인 객체 수가 예상 범위 내에 들어 있는지 확인해야 한다. 

한편 단명 도메인 객체 역시 앞서 언급했던 부유 가비지 문제를 일으키는 또 다른 원인이 될 가능성이 농후하다. 누수를 일으키는 도메인 객체는 종종 GC 마킹 시간을 중가시키는 주범으로 알려져 있다. 근본적으로 이유는 하나의 단명 객체가 긴 전체 객체 체인에 걸쳐 살아남기 때문이다.

많은 애플리케이션에서 도메인 객체는 탄광 속의 카나리아와 같은 역할을 한다. 사실 도메인 객체는 비즈니스 관심사를 가장 분명하게, 자연스럽게 나타낸 객체라서 메모리 누수에 더 취약합니다. 성능을 중요시하는 개발자는 도메인 객체의 도메인을 인식하고 그에 알맞은 크기의 작업 세트가 배정되도록 해야 한다. 

### 종료화 안 하기

자바 finalize() 메서드는 C++의 리소스 획득 초기화(RAII) 패턴과 마찬가지로 자동으로 리소스를 관리하려고 만든 장치이다. RAII 패턴에서는 객체를 해체할 때 자동으로 리소스를 해제/정리하는 해체기 메서드가 있다. 

기본 유스케이스는 간단하다. 어떤 객체가 생성되면 이 객체는 리소스를 소유하고 그 소유권은 객체가 살아 있는 한 지속된다. 그러다 객체가 죽음을 맞이하면 리소스 소유권을 자동으로 내어준다.

프로그래머가 파일 핸들을 열고 나서 더 이상 필요 없으면 close() 함수를 호출해야 하는데 깜빡 잊어버리는 일이 정말 많다.

**무용담 : 정리하는 걸 깜빡하다**

타 서비스에 TCP로 접속해서 권한 및 자격 정보를 받아오는 서비스에서 close()함수가 호출되지 않아서 TCP 접속이 계속 열려 있는 상태로 애플리케이션이 배포된 운영계 서버에서 파일 핸들러 리소스는 점점 고갈괬고 같은 머신에 상주한 다른 프로세스에도 영향을 미쳤다. 

**왜 종료화로 문제를 해결하지 않을까?**

Object의 finalize() 메서드는 자바 태동기부터 있었다. 기본적으로 노옵(no-op : 아무것도 하지 않는)메서드이다. 하지만 이 메서드는 오버라이드해서 특정한 로직을 부여할 수 있다. 자바 문서에는 다음과 같이 씌어 있다.

> 어떤 객체가 더 이상 자신을 참조하지 않는다고 가비지 수집기가 판단하면 그 객체에 있는 finalize() 메서드를 호출한다. 서브 클래스는 finalize() 메서드를 오버라이드해서 시스템 리소스를 처분하는 등 기타 정리 작업을 수행한다.
> 

실제로는 JVM 가비지 수집기가 특정 객체의 사망 사실을 분명히 알리는 서브시스템 역할을 한다. 다만, finalize() 메서드를 지원하는 타입으로 생성된 객체 중 finalize() 메서드를 오버라이드한 객체는 가비지 수집기가 특별하게 처리한다. 종료화 가능한 개별 객체는 java.lang.Object 생성자 바디에서 성공 반환되는 시점에 해당 객체를 등록하는 식으로 JVM에 구현돼 있다.

여기서 꼭 알아야 할 핫스팟의 구현 상세는, VM에는 표준 자바 명령어 외에도 구현체에 종속된 바이트코드가 있다는 사실이다. 이런 특수한 바이트코드는 어떤 특별한 상황에 맞게 표준 바이트코드를 재작성하기 위해 사용한다. 

표준 자바 바이트코드 및 핫스팟 전용 바이트코드 전체 목록은 hotspot/share/interpreter/bytecodes.cpp 파일에 있다. 그중 return_register_finalizer가 좀 전에 설명한 내용에 해당하는 바이트코드이다. 이 바이트코드는 가령 JVMTI가 Object.<init>() 에 해당하는 바이트코드를 재작성할 수 있기 때문에 필요하다. 표준을 정확히 준수하려면 Object.<init>()이 완료되는 정확한 지점을 식별해야 하는데, return_register_finalizer가 바로 이 지점을 표시하는 데 사용된다. 

실제로 종료화가 필요한 객체로 등록하는 코드는 핫스팟 인터프리터에 있다. src/hotspot/cpu/x86/c1_Runtime.cpp 파일을 보면 x86 전용 핫스팟 인터프리터의 코어가 나온다. 핫스팟은 저수준 어셈블리/기계어를 아주 많이 활용하므로 이런 코드는 프로세서에 종속된 코드이다. 등록 코드는 register_finalizer_id 케이스 문에 들어 있다. 

가비지 수집 중 즉시 회수되지 않고 종료화 대상으로 등록된 객체는 다음과 같이 수명이 연장된다.

1. 종료화가 가능한 객체는 큐로 이동한다.
2. 애플리케이션 스레드 재시작 후, 별도의 종료화 스레드가 큐를 비우고 각 객체마다 finalize() 메서드를 실행한다. 
3. finalize()가 종료되면 객체는 다음 사이클에 진짜 수집될 준비를 마친다. 

종료화할 객체는 모두 GC 마킹을 해서 도달 불가능한 객체로 인식시키고, 종료화한 다음엔 반드시 GC를 재실행해서 데이터를 다시 수집해야 한다. 즉, 종료화 가능한 객체는 적어도 한번의 GC 사이클은 더 보존된다. 이는 테뉴어드 세대 객체의 경우 상당히 긴 시간이 될 수도 있다. 

finalize()는 다른 문제점도 있다. 이를테면, 종료화 스레드 실행 도중 메서드에서 예외가 발생하면 어떻게 될까? 이때 유저 애플리케이션 코드 내부에는 아무런 컨텍스트도 없기 때문에 발생한 예외는 그냥 무시된다. 종료화 도중 발생한 오류는 개발자도 어쩔 수 없다.

종료화에 블로킹 작업이 있을지 모르니 JVM이 스레드를 하나 더 만들어 finalize() 메서드를 실행해야 한다. 따라서 새 스레드를 생성/실행하는 오버헤드는 감수해야 한다. 

종료화를 구현한 코드는 대부분 자바로 작성돼 있다. JVM은 대부분의 필요한 작업을 처리하는 애플리케이션 스레드와 함께 별도의 스레드를 만들어 종료화를 수행한다. 핵심 기능은 패키지-프라이빗 클래스 java.lang.ref.Finalizer에 구현되어 있고 코드가 직관적이라 알아보기 쉽다. 

종료화 구현체는 FinalReference 클래스에 크게 의존한다. 이 클래스의 슈퍼클래스가 바로 런타임이 특별한 경우로 인식하는 java.lang.ref.Reference 클래스이다. FinalReference 객체는 GC 서브시스템이 특별하게 처리하며, VM과 자바 코드 사이에 흥미진진한 상호작용을 제공하는 매커니즘으로 이루어져있다. 

그러나 기술적으로는 흥미로울지 몰라도 자바와 C++, 두 언어의 메모리 관리 개념은 근본부터 달라서 종료화를 구현한 코드는 치명적인 결함을 지닐 수 밖에 없다. C++에서 동적 메모리는 수동 처리, 다시 말해 어디까지나 프로그래머가 직접 객체 수명을 명시적으로 관리하는 체제이다. 따라서 객체가 삭제되면 바로 해체되므로 리소스 획득/해제는 해당 객체의 수명과 단단히 엮여 있다. 

그에 반해 자바의 메모리 관리 서브 시스템은 할당할 가용 메모리가 부족하면 그때그때 반사적으로 가비지 수집기를 실행시킨다. 가비지 수집이 언제 일어날지는 아무도 모르기 때문에 객체가 수집될 때에만 실행되는 finalize() 메서드도 언제 실행될지 알 길이 없다.

다시 말해 가비지 수집은 딱 정해진 시간에 실행되는 법이 없으므로 종료화를 통해 자동으로 리소스를 관리한다는 것 자체가 어불성설이다. 리소스 해제와 객체 수명을 엮는 장치가 따로 없으니 항상 리소스가 고갈될 위험에 노출돼 있는 셈이다.

종료화는 당초 의도했던 목적과는 잘 맞지 않는다. 그래서 오래전부터 오라클을 일반 애플리케이션 코드에 종료화를 사용하지 말라고 개발자들에게 권고해왔고, 자바 9부터는 Object.finalize()는 디프리케이트되었다.

**try-with-recources**

자바 7 이전까지 리소스를 닫는 일은 순전히 개발자의 몫이었다. 자바 7부터 언어 자체에 추가된 try-with-resources 생성자를 이용하면 try 키워드 다음의 괄호 안에 리소스를 지정해서 생성할 수 있다. 이로써 try 블록이 끝나는 지점에 개발자가 close() 메서드 호출을 깜빡 잊고 빠뜨려도 자동으로 호출된다.

종료화와 try-with-resources는 사실상 설계 의도는 같으나 근본적으로 전혀 다른 메커니즘이다.

종료화는 런타임 내부 깊숙한 곳에 있는 어셈블리 코드에 기반해 객체를 미리 등록하고 특별한 GC 작업을 수행한다. 그런 다음, 가비지 수집기를 이용해 레퍼런스 큐와 별도의 전용 종료화 스레드를 동원해 정리 작업을 한다. 

반면, try-with-resources는 순수한 컴파일 타임 기능이다. 컴파일 하면 평범한 바이트코드로 바뀌는, 다른 런타임 로직돠는 무관한 일종의 간편 구문이다. 단, try-with-resources는 상당히 큰 바이트코드로 변환되므로 JIT 컴파일러가 인라이닝하고 메서드를 컴파일 하는 과정에 좋지 않은 영향을 끼칠 가능성이 있다. 

### 메서드 핸들

invokeddynamic 명령어는 자바 7에서 처음 선보인 주요 기능이다. 이 명령어 덕분에 호출부에서 실행할 메서드를 아주 유연하게 결정할 수 있게 됐다. 핵심 포인트는 invokeddynamic 호출부가 실제로 어느 메서드를 호출할지 런타임 전까지 결정되지 않는다는 점이다. 

대신 호출부가 인터프리터에 이르면 특수한 보조 메서드가 호출되고, 이 특수 보조 메서드는 호출부에서 호출됐어야 할 실제 메서드를 가리키는 객체를 반환한다. 이 객체를 호출 대상이라고 하며, 호출부 내부에 가미됐다고 표현한다.

여기서 핵심은 바로 메서드 핸들이다. 메서드 핸들은 invokedynamic 호출부에 의해 호출되는 메서드를 나타낸 객체이다. 리플렉션과 어느 정도 개념이 비슷하지만, 리플렉션은 자체 한계 때문에 invokedynamic와 더불어 사용하기가 불편하다.

그래서 자바 7부터 일부 클래스, 패키지(java.lang.invoke.MethodHandle) 가 추가돼서 실행 가능한 메서드의 레퍼런스를 직접 반영할 수 있게 되었다. 하부 메서드를 실행할 수 있는 다양한 메서드가 메서드 핸들 객체에 내장되어 있다. 그중 invoke()를 제일 많이 쓰지만, 주요 인보커를 조금 변형한 메서드와 일부 헬퍼가 추가되었다.

리플렉션 호출처럼 메서드 핸들의 하부 메서드의 시그니처는 자유롭기 때문에 메서드 핸들에 있는 인보커 메서드는 최대한 융동성 있게 관대한 시그니처를 지니고 있어야 한다. 하지만 그 밖에도 메서드 핸들은 리플렉션으로 할 수 없는 기능을 가지고 있다.

다음과 같이 재귀호출하는 단순한 코드가 있다.

```java
Method m = ...
Object receiver = ...
Object o = m.invoke(receiver, new Object(), new Object());
```

이 코드를 컴파일 하여 바이트코드로 변환되었을 때, 전체 호출 시그니처는 **invoke:(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;** 이다. 이 메서드는 하나의 객체 인수와 리플렉션 호출에 전달한 가변 인수들을 죽 받는다. 결국 Object를 반환하므로 컴파일 타임에는 이 메서드가 어떻게 호출될지 전혀 알 수 없다. 런타임 직전까지 모든 가능성을 찔러봐야 한다.

그런데 메서드를 이렇게 호출하는건 너무 일반적이기 때문에 수신자와 Method 객체가 안 맞거나 매개변수 목록에 조금이라도 오류가 생기면 런타임에 실패할 가능성이 크다.

메서드 핸들을 쓰는 코드는 어떨까?

```java
MethodType mt = MethodType.methodType(int.class);
MethodHandles.Lookup l = MethodHandles.lookup();
MethodHandle mh = l.FindVirtual(String.class, "hashCode", mt);

String receiver = "b";
int ret = (int) mh.invoke(receiver);
System.out.println(ret);
```

두 부분으로 나누어 호출하고 있다. 먼저 메서드 핸들을 룩업하고 그다음에 호출한다. 실제 시스템에서는 이 두 부분이 시점 또는 코드 위치 측면에서 멀찍이 분리되어 있을 수도 있다. 메서드 핸들은 안정된 불변 객체라서 나중에 쓸 목적으로 보관, 캐시하기가 쉽다.

메서드 핸들을 룩업하는 부분이 똑같아 보일 수 있으나, 리플렉션이 처음 나왔을 때부터 문제였던 액세스 제어 이슈를 바로잡을 수 있다.

클래스가 처음 로딩되면 VM은 바이트코드를 전수 검사한다. 이 과정에서 액세스 권한이 없는 메서드를 클래스가 악의적으로 호출하려고 시도하는지 검사한다. 액세스 불가한 메서드를 호출하려고 하면 결국 클래스 로딩 프로세스는 실패할 것이다. 

한번 로딩된 클래스는 성능 문제가 있어 두번 다시 검사하지 않는다. 리플렉션 코드는 이런 틈새를 파고들어 나쁜 짓을 할 수도 있다.

메서드 핸들 API는 룩업 컨텍스트라는 방식으로 접근한다. 일단 MethodHandles.lookup() 메서드를 호출해 컨텍스트 객체를 생성하는데, 이 메서드가 반환한 불변 객체에는 컨텍스트 객체를 생성한 지점에서 액세스 가능한 메서드 및 필드를 기록한 상태 정보가 있다. 

따라서 컨텍스트 객체는 바로 사용해도 되고 저장했다가 나중에 써도 된다. 이런 유연성 덕분에 클래스에 있는 프라이빗 메서드를 선택적으로 액세스할 수 있게 되었다. 반면에, 리플렉션은 setAccessible()라는 꼼수밖에는 다른 도리가 없어서 자바의 안전한 액세스 제어 체계에 큰 허점을 노출시킨다.