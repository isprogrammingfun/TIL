## JVM의 코드 실행

### 바이트코드 해석

JVM 인터프리터는 일종의 스택 머신처럼 작동하므로 물리적 CPU 와는 달리 계산 결과를 바로 보관하는 레지스터는 없다. 대신 작업할 값은 모두 평가 스택에 놓고 스택 머신 명령어로 스택 최상단에 위치한 값을 변환하는 식으로 작동한다. 

JVM은 다음 세 공간에 주로 데이터를 담아 놓는다.

- 평가 스택 : 메서드별로 하나씩 생성된다.
- 로컬 변수 : 결과를 임시 저장한다. (특정 메서드별로 존재한다)
- 객체 힙 : 메서드끼리, 스레드까리 공유된다.

다음은 VM 작업을 의사코드 형태로 나타낸 것이다. 

![image1](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/90a6ed59-44ba-49b8-928c-86d98c62fe74)

인터프리터는 우측 서브트리를 계산해서 x 콘텐츠와 비교할 값을 결정한다.

![image2](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/b202429a-0cbd-4141-b0d5-1badce5c0078)

다음 서브트리 제일 앞에 있는 값이 스택에 로드된다. 

![image3](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/8f6e1646-a8af-4f4f-ae94-33c080ac5968)

이제 또 다른 정숫값 1도 스택에 로드된다. 실제 JVM에서 이런 값들은 클래스 파일의 상수 영역에서 로드될것이다. 

![image4](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/132ffb3c-f41b-47c4-a982-c25b9d2f2f07)

그리고 스택 위에 나란히 얹어놓은 두 원소를 더하고 싹 지운 다음, 덧셈 결괏값으로 대체한다.

![image5](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/dc7fa959-6fc4-4aa7-b40c-02a402317f1d)

이제 이 덧셈 결괏값을, 다른 서브트리를 평가하는 내내 평가 스택에 있었던 x와 비교한다. 

**JVM 바이트코드 개요**

JVM에서 각 스택 머신 작업 코드(옵코드)는 1바이트로 나타낸다. 따라서 옵코드는 0부터 255까지 지정 가능하며, 그 중에서 약 200개를 사용하고 있다. 바이트 코드 명령어는 스택 상단에 위치한 두 값의 기본형을 구분할 수 있게 표기한다. 예를 들어 iadd와 dadd는 각각 int값과 double 값이다. 바이트코드 명령어는 대부분 한쪽은 각 기본형, 다른 한쪽은 참조형으로 쓸 수 있게 패밀리(군, 집단) 단위로 구성된다. 예를 들어 store 패밀리는 명령어마다 제각기 의미가 있다. destore는 ‘스택 상단을 double형 지역 변수로 스토어하라’, astore는 ‘스택 상단을 참조형 지역 변수로 스토어하라’는 뜻이다. 둘 다 지역 변수와 주어진 값의 타입이 서로 맞아야 한다. 

자바는 처음부터 이식성을 염두에 두고 설계된 언어이다. 그래서 JVM은 빅 엔디언, 리틀 엔디언 하드웨어 아키텍처 모두 바이트코드 변경없이 실행 가능하도록 명세에 규정되어 있다. 따라서 JVM 바이트코드는 반대쪽 엔디언을 따르는 하드웨어에서도 소프트웨어상의 차이점을 처리해야 하므로 둘 중 어느 엔디언을 따를지 결정해야 한다. 바이트코드는 빅 엔디언이므로 최상위 바이트가 가장 먼저 온다.

load 같은 옵코드 군에는 단축형이 있어서 인수를 생략할 수 있고 그만큼 클래스 파일의 인수 바이트 공간을 절약할 수 있다. 특히 현재 객체를 스택 상단에 넣는 aload_0 같은 명령어는 워낙 자주 쓰여서 클래스 파일 크기가 상당히 줄어든다.

자바 1.0 이후 새로 추가된 옵코드는 invokeddynamic 하나뿐이다. jsr과 ret 두 옵코드는 디프리케이드되었다. 

단축형 명령어, 타입별 명령어를 쓰다보니 필요한 옵코드 개수가 급증했고 여러 옵코드가 개념상 동일한 작업을 나타내는 경우도 있다. 그래서 사실 바이트코드는 개념적으로는 아주 단순하지만, 바이트코드로 나타낼 수 있는 기본 작업보다 훨씬 많은 옵코드가 할당되어 있다.  다음은 스택에 데이터를 넣고 빼는 옵코드로 구성된 로드/스토어 카테고리이다.

| 패밀리 명 | 인수 | 설명 |
| --- | --- | --- |
| load | (i1) | 지역 변수 i1 값을 스택에 로드한다. |
| store | (i1) | 스택 상단을 지역 변수 i1에 저장한다. |
| ldc | c1 | CP#c1이 카리키는 값을 스택에 로드한다. |
| const |  | 단순 상숫값을 스택에 로드한다. |
| pop |  | 스택 상단에서 값을 제거한다. |
| dup |  | 스택 상단에 있는 값을 복제한다. |
| getField | c1 | 스택 상단에 위치한 객체에서 CP#c1이 가리키는 필드명을 찾아 그 값을 스택에 로드한다. |
| putField | c1 | 스택 상단의 값을 CP#c1이 가리키는 필드에 저장한다. |
| getstatic | c1 | CP#c1이 가리키는 정적 필드값을 스택에 로드한다. |
| putstatic | c1 | 스택 상단의 값을 CP#c1이 가리키는 정적 필드에 저장한다.  |

ldc와 const는 분명히 구별해야 한다. ldc는 현재 클래스의 상수 풀에 있는 상수를 로드하는 바이트 코드이다. 스트링, 기본형 상수, 클래스 리터럴, 기타 프로그램 실행에 필요한 상수가 여기에 해당한다. const는 매개변수 없이 aconst_null, dconst_0, iconst_m1 형태로 진짜 상수만 로드하는 옵코드이다. 

다음은 산술 바이트코드이다. 기본형에만 적용되며 순수하게 스택 기반으로 연산을 수행하므로 인수는 없다. 

| 패밀리 명 | 설명 |
| --- | --- |
| add | 스택 상단의 두 값을 더한다. |
| sub | 스택 상단의 두 값을 뺀다. |
| div | 스택 상단의 두 값을 나눈다. |
| mul | 스택 상단의 두 값을 곱한다. |
| (cast) | 스택 상단의 값을 다른 기본형으로 캐스팅한다. |
| neg | 스택 상단의 값을 부정한다. |
| rem | 스택 상단의 두 값을 나눈 나머지를 구한다. |

다음은 흐름을 제어하는 바이트코드이다. 소스 코드의 순회, 분기물을 바이트코드 수준으로 표현하는 옵코드들이다. 자바 for, if, while, switch문을 컴파일하면 모두 이런 흐름 제어 옵코드로 변환된다.

| 패밀리 명 | 인수 | 설명 |
| --- | --- | --- |
| if | (i1) | 조건이 참일 경우, 인수가 가리키는 위치로 분기한다. |
| goto | i1 | 주어진 오프셋으로 무조건 분기한다. |
| tableswitch |  |  |
| lookupswitch |  |  |

바이코드가 몇 개 안 되어 보이지만, if 옵코드 패밀리에 속한 옵코드가 상당히 많아서 실제 가짓수는 꽤 된다. jsr, ret 역시 흐름 제어 패밀리에 속한 바이트코드지만 자바 6 이후로 디프리케이트 되었다. 

다음은 메서드 호출 바이트코드이다. 자바 프로그램에서 새 메서드로 제어권을 넘기는 유일한 장치이다. 자바 플랫폼은 지역 흐름 제어와 다른 메서드로 제어권을 넘기는 행위를 분명히 구분한다. 

| 옵코드명 | 인수 |  설명 |
| --- | --- | --- |
| invokevirtual | c1 | CP#c1이 카리키는 메서드를 가상 디스패치를 통해 호출한다 |
| invokespecial | c1 | CP#C1이 가리키는 메서드를 특별한 디스패치를 통해 호출한다 |
| invokeinterface | c1, count, 0 | CP#c1이 가리키는 인터페이스 메서드를 인터페이스 오프셋 룩업을 이용해 호출한다 |
| invokestatic | c1 | CP#c1이 가리키는 정적 메서드를 호출한다 |
| invokedynamic | c1, 0, 0 | 호출해서 실행할 메서드를 동적으로 찾는다 |

JVM 설계 구조상 메서드 호출 옵코드를 명시적으로 사용해야 하므로 기계어에는 이와 동등한 호출 작업이 없다. 대신 JVM 바이트코드는 몇 가지 전문 용어를 사용한다. 호출부는 메서드 내부에서 다른 메서드를 호출한 지점이다. 비정적 메서드 호출의 경우, 어느 객체에 있는 메서드인지 반드시 해석해야 하는데, 이렇게 찾은 객체를 수신자 객체, 이 객체의 런타임 타입을 수신자 타입이라고 한다. 정적 메서드 호출은 항상 invokestatic으로 컴파일되며 수신자 객체는 없다. 

자바 객체가 메서드 호출을 할 때 실제 호출 컨텍스트에 따라 세 바이트코드 (invokevirtual, invokespecial, invokeinterface) 중 하나로 바뀐다. 간단한 자바 코드를 작성해서 javap로 역어셈블 해보면 어떤 조건일 때 특정 바이트코드로 바뀌는 지 바로 확인할 수 있어 좋다.

인스턴스 메서드 호출은 보통 invokevirtual로 변환되며, 자바 인터페이스에 선언된 메서드를 호출할 경우 invokeinterface로 바뀐다. 또 컴파일 타임에 디스패치할 메서드를 특정할 수 있는 경우 invokespecial 명령어로 컴파일된다.

invokedynamic은 자바 8 이후로 자바 언어의 핵심으로 급부상했고 자바 언어의 고급 기능을 지원하는 데 활용되고 있다. invokedynamic 유스케이스로 람다 표현식만큼 확실한 건 없겠지만, 그밖에도 이 옵코드는 제이루비, 내쉬혼 처럼 JVM에서 작동하는 논자바 언어를 비롯해 점점 더 많은 자바 프레임워크에서 사용되고 있다. 

다음은 플랫폼 옵코드이다. 객체별로 힙 저장 공간을 새로 할당하거나, 고유 락을 다루는 명령어들이다.

| 옵코드명 |  인수 |  설명 |
| --- | --- | --- |
| new |  c1 | CP#c1이 가리키는 타입의 객체에 공간을 할당한다 |
| newarray | prim |  기본형 배열에 공간을 할당한다 |
| anewarray | c1 | CP#c1이 가리키는 타입의 객체 배열에 공간을 할당한다 |
| arraylength |  | 스택 상단에 위치한 객체를 그 길이로 치환한다 |
| monitorenter |  | 스택 상단의 객체 모니터를 잠금한다 |
| monitorexit |  | 스택 상단의 객체 모니터를 잠금 해제한다 |

newarray 및 anewarray는 옵코드 실행 시 할당할 배열 길이가 스택 상단에 놓여져 있다.

바이트코드는 구현 복잡도에 따라 대단위 바이트코드와 소단위 바이트코드로 명확히 구분된다.

가령, 산술 연산은 매우 소단위 작업이고 핫스팟에서 순수 어셈블리어로 구현되는 반면, 대단위 연산(상수 풀 룩업, 특히 메서드 디스패치가 필요한 작업들)은 핫스팟 VM을 다시 호출할 수밖에 없다.

인터프리터로 해석된 코드의 세이프포인트는 JVM이 어떤 관리 작업을 수행하고 내부 상태를 일관되게 유지하는데 필요한 지점이다. 그리고 세이프포인트에는 객체 그래프가 들어 있다.

일관된 상태를 유지하려면 JVM이 관리 작업 수행 도중 공유 힙이 변경되지 않게 모든 애플리케이션 스레드를 멈춰야 한다. 이런 작업을 어떻게 해야 할까? 먼저, JVM 애플리케이션 스레드 하나하나가 진짜 OS 스레드임을 상기해야 한다. 또, 인터프리티드 메서드를 실행하는 스레드에 대해 옵코드가 디스패치되는 시점에서 애플리케이션 스레드가 실행하는 것은 유저 코드가 아니라 JVM 인터프리터 코드이다. 따라서 힙 상태 일관성이 보장되고 애플리케이션 스레드를 멈출 수 있다. 따라서 바이트코드 사이사이가 애플리케이션 스레드를 멈추기에 이상적인 시점이자, 가장 단순한 세이프포인트이다. 

**단순 인터프리터**

가장 단순한 인터프리터는 switch 문이 포함된 while 루프 형태일 것이다. 오슬롯 프로젝트가 이런 유형의 인터프리터로 교육용으로 JVM 인터프리터 일부를 구현했다. 이 인터프리터의 execMethod() 메서드는 단일 메서드의 바이트코드를 해석한다. 정수 계산, “Hello World” 출력 정도를 할 수 있는 옵코드가 구현되어 있다. 

**핫스팟에 특정한 내용**

핫스팟은 상용 제품급 JVM이자, 완전한 구현체이다. 그뿐만 아니라, 인터프리티드 모드에서도 빠르게 실행될 수 있도록 여러 고급 확장 기능을 지니고 있다. 또한 핫스팟은 템플릿 인터프리터라서 시작할 때 마다 동적으로 인터프리터를 구축한다. 이런 이유로 이해하기가 훨씬 더 복잡하고 인터프리터 소스 코드조차 분석하기가 어려웠다. 게다가 핫스팟은 성능을 조금이라도 높이기 위해 상당히 많은 어셈블리어 코드로 작성돼 있다. 더 나아가 VMSpec에 없는 핫스팟 전용 바이트코드까지 정의해서 사용한다. 특정 옵코드의 일반적인 유스테이스와 핫(hot)하게 쓰는 경우를 차별화하려는 의도다. 

이러한 설계 방식은 특이 사례를 다루는데 도움이 된다. 예를 들어, final  메서드는 오버라이드할 수 없으니 javac로 컴파일하면 invokespecial 옵코드가 나오리라 예상할 수 있다. 그러나 자바 언어 명세에는 다음과 같은 문구가 있다.

> final  메서드를 final 아닌 메서드로 변경하는 건 기존 바이너리와의 호환성을 깨뜨리지 않는다.
> 

다음과 같은 자바 코드가 있다.

```java
public class A {
	public final void fMethod() {

	}
}

public class CallA {
	public void otherMethod(A obj) {
			obj.fMethod();
	}
}
```

final 메서드 호출부가 invokespecial로 컴파일되면 CallA::otherMethod는 다음 바이트코드로 바뀔 것이다.

```java
public void otherMethod()
	Code:
		0: aload_1
		1: invokespecial #4 //Method A.fMethod:()V
		4: return
```

이때 A 클래스에서 fMethod() 메서드를 논final 메서드로 바꾸면 이 메서드는 서브클래스(B)에서 오버라이드 가능한다. 그럼 이제 B 인스턴스를 otherMethod() 메서드의 인수로 넘기면 어떻게 될까? 바이트코드 수준에서는 invokespecial 명령어가 실행될 테니 메서드를 잘못 호출할 것이다. 이것은 자바의 객체 지향 원칙을 위배하는 것으로, 특히나 리스코프 치환 원칙을 위배한다. 

그러므로 final 메서드 호출은 반드시 invokevirtual 명령어로 컴파일돼야 하지만, final 메서드는 오버라이드가 안된다는 점을 JVM도 알고 있기 때문에 핫스팟 인터프리터에는 final 메서드를 디스패치하는 전용 프라이빗 바이트코드가 있다. 

### AOT와 JIT 컴파일

**AOT 컴파일**

AOT의 목표는 프로그램을 실행할 플랫폼과 프로세서 아키텍처에 딱 맞는 실행 코드를 얻는 것이다. 이렇게 대상이 고정된 바이너리는 프로세서별로 특수한 기능을 활용해 프로그램 속도를 높일 수 있다. 

하지만 대부분의 실행 코드는 자신이 어떤 플랫폼에서 실행될지 모르는 상태에서 생성되므로 AOT 컴파일은 자신이 사용 가능한 프로세서 기능에 대해 가장 보수적인 선택을 해야한다. 어떤 기능이 있을 거란 전제하에 컴파일한 코드가 실제로 그렇지 못한 환경에서 실행되면 바이너리가 전혀 작동하지 않을 것이다.  결국, AOT 컴파일한 바이너리는 CPU 기능을 최대한 활용하지 못하는 경우가 다반사고 성능 향상의 숙제가 남는다. 

**JIT 컴파일**

JIT 컴파일은 런타임에 프로그램을 고도로 최적화한 기계어로 반환하는 기법이다. 핫스팟을 비롯한 대부분의 주요 상용 JVM이 이 방식으로 작동된다. 프로그램의 런타임 실행 정보를 수집해서 어느 부분이 자주 쓰이고, 어느 부분을 최적화해야 가장 효과가 좋은지 프로파일을 만들어 결정을 내린다. 이러한 기법을 프로파일 기반 최적화(PGO)라고 한다. 

JIT 서브시스템은 실행 프로그램과 VM 리소스를 공유하므로 프로파일링 및 최적화 비용 및 성능 향상 기대치 사이의 균형을 맞춰야 한다. 

애플리케이션을 실행할 때마다 성능이 심한 편차를 보이는 현상은 흔하다. 그래서 핫스팟은 프로파일링 정보를 보관하지 않고 VM이 꺼지면 일체 폐기한다. 따라서 항상 프로파일은 처음부터 다시 만들어진다.

**AOT 컴파일 VS JIT 컴파일**

- AOT 컴파일
    - AOT는 소스 코드에서 바로 기계어가 생성되고 컴파일 단위별로 대응되는 기계어를 어셈블리로 바로 사용할 수 있다. 그래서 코드의 성능 특성이 그리 복잡하지 않다.
    - AOT는 최적화 결정을 내리는 데 유용한 런타임 정보를 포기하는 만큼 장점이 상쇄된다.
    - AOT 컴파일 도중 프로세서의 특정 기능을 타깃으로 정하면 해당 프로세스에서만 사용 가능한 실행 코드가 만들어진다. 이는 저지연 또는 극단적으로 성능이 중요한 유스케이스에선 유용한 기법일 것이다.
    - 확장성이 떨어진다
- JIT 컴파일
    - 핫스팟은 새로 릴리즈를 할 때 마다 새로운 프로세서 기능에 관한 최적화 코드를 추가할 수 있고, 애플리케이션은 기존 클래스 및 JAR 파일을 다시 컴파일하지 않아도 신기능을 십분 활용할 수 있다.

자바 프로그램은 AOT 컴파일을 할 수 없다 라는 말은 틀렸다. 이미 수년 전부터 자바 프로그램의 AOT 컴파일을 지원하는 상용 VM이 나왔고 AOT 컴파일을 자바 애플리케이션을 배포하는 주요 경로로 활용하는 환경도 있다.

### 핫스팟 JIT 기초

핫스팟의 기본 컴파일 단위는 전체 메서드이다. 따라서 한 메서드에 해당하는 바이트코드는 한꺼번에 네이티브 코드로 컴파일된다.

 핫스팟은 핫 루프를 온-스택 치환(OSR)이라는 기법을 이용해 컴파일하는 기능도 지원한다. OSR은 어떤 메서드가 컴파일할 만큼 자주 호출되지만 않지만, 컴파일하기 적합한 루프가 포함돼 있고 루프 바디 자체가 메서드인 경우 사용한다. 

**klass 워드, vtable, 포인터 스위즐링**

핫스팟은 멀티스레드 C++ 애플리케이션이다. 그래서 실행 중인 모든 자바 프로그램은 OS 관점에서는 실제로 한 멀티스레드 애플리케이션의 일부일 뿐이다. 싱글 스레드 자바 애플리케이션이라고 해도 결국 VM 스레드와 함께 실행되는 구조이다. 

JIT 컴파일 서브시스템을 구성하는 스레드는 핫스팟 내부에서 가장 중요한 스레드들이다. 컴파일 대상 메서드를 찾아내는 프로파일링 스레드와 실제 기계어를 생성하는 컴파일러 스레드도 다 여기에 포함된다. 

컴파일 대상으로 선택된 메서드는 컴파일러 스레드에 올려놓고 백그라운드에서 컴파일한다. 최적화된 기계어가 생성되면 해당 klass의 vtable은 새로 컴파일된 코드를 가리키도록 수정된다. 이런 vtable 포인터를 업데이트 하는 작업을 포인터 스위즐링이라고 한다.

**JIT 컴파일 로깅**

성능 엔지니어라면 다음 JVM 스위치를 반드시 알고 있어야 한다.

```java
-XX:+PrintCompilation
```

이 스위치를 켜면 컴파일 이벤트 로그가 표준 출력 스트임에 생성되므로 성능 엔지니어는 이 로그를 보고 어떤 메서드가 컴파일되고 있는지 파악할 수 있다.

PrintCompilation 출력 결과는 비교적 형식이 단순하다. 메서드가 컴파일된 시간(VM 시작 이후 ns)가 제일 먼저 나오고, 그 다음에 이번 차례에 컴파일된 메서드의 순번이 표시된다. 그 밖의 필드는 다음과 같다.

- n : 네이티브 메서드이다.
- s : 동기화 메서드이다.
- ! : 예외 핸들러를 지닌 메서드이다.
- % : OSR을 통해 컴파일된 메서드이다.

PrintCompilation만으로는 자세한 정보를 파악하기 어렵기 때문에 핫스팟 JIT 컴파일러가 어떤 결정을 내렸는지 더 자세한 정보는 다음 플래그로 볼 수 있다.

```java
-XX:+LogCompilation
```

LogCompilation은 진단용 옵션이라 다음 플래그를 추가해 진단 모드로 해제해야 한다.

```java
-XX:+UnlockDiagnosticVMOptions
```

VM이 바이트코드를 네이티브 코드로 어떻게 최적화했는지, 큐잉은 어떻게 처리했는지 관련 정보를 XML 태그 형태로 담은 로그파일로 출력하라는 지시이다.

**핫스팟 내부의 컴파일러**

핫스팟 JVM에는 C1,C2라는 두 JIT 컴파일러가 있다. 각각 클라이언트 컴파일러, 서버 컴파일러라고 부르기도 한다. 역사적으로 C1은 GUI 애플리케이션 및 기타 클라이언트 프로그램에, C2는 실행 시간이 긴 서버 애플리케이션에 주로 사용됐지만, 요즘 자바 애플리케이션에서는 이렇게 구분하는 기준이 뚜렷하지 않고 핫스팟은 새로운 환경에 맞게 최대한 성능을 발휘하도록 변화했다. 

C1,C2 컴파일러 모두 핵심 측정값, 즉 메서드 호출 횟수에 따라 컴파일이 트리거링 된다. 호출 횟수가 특정 한계치에 이르면 그 사실을 VM이 알림 받고 해당 메서드를 컴파일 큐에 넣는다.

컴파일 프로세스는 가장 먼저 메서드의 내부 표현형을 생성한 다음, 인터프리티드 단계에서 수집한 프로파일링 정보를 바탕으로 최적화 로직을 적용한다. 

같은 코드라도 C1와 C2가 생성한 내부 표현형은 전혀 다르다. C1은 C2보다 컴파일 시간도 더 짧고 단순하게 설계된 까닭에 C2 처럼 풀 최적화는 안 한다.

**핫스팟의 단계별 컴파일**

자바 6부터 JVM은 단계별 컴파일 모드를 지원한다. 인터프리티드 모드로 실행되다가 단순한 C1 컴파일 형식으로 바뀌고, 다시 이를 C2가 보다 고급 최적화를 수행하는 방식으로 단계를 바꾸는 것이다. 

advancedThreadsholdPolicy.hpp 소스 파일을 보면 VM 내부에는 5개 실행 레벨이 존재한다.

- 레벨 0 : 인터프리터
- 레벨 1 : C1 - 풀 최적화(프로파일링 없음)
- 레벨 2 : C1 - 호출 카운터 + 백엣지 카운터
- 레벨 3 : C1 - 풀 프로파일링
- 레벨 4 : C2

이 모든 레벨을 다 거치는 것은 아니고, 컴파일 방식마다 경로가 다르다.

| 경로 |  설명 |
| --- | --- |
| 0-3-4 | 인터프리터, C1 - 풀 프로파일링, C2 |
| 0-2-3-4 | 인터프리터, C2는 바쁘니까 재빨리 C1 컴파일 후 C1 풀 컴파일, 그 다음에 C2 |
| 0-3-1 | 단순 메서드 |
| 0-4 | 단계별 컴파일 안 함(C2로 직행) |

단순 메서드는 일단 인터프리티드로 시작하지만, C1은 이 메서드가 정말 단순한지 판단할 수 있다. 따라서 C1 컴파일러가 C2보다 더 나은 코드를 낼 리 없기 때문에 컴파일은 여기서 종료된다.

단계별 컴파일은 꽤 오래전부터 디폴트여서 성능 튜닝 시 이 부분을 조정할 일은 거의 없다. 다만, 컴파일드 메서드의 자동 로직이 복잡해지기 쉽고 부주의한 엔지니어를 잘못된 길로 이끌 가능성이 있으므로 작동 원리 정도는 알아두는 게 좋다.

### 코드 캐시

JIT 컴파일드 코드는 코드 캐시라는 메모리 영역에 저장된다. 이곳엔 인터프리터 부속 등 VM 자체 네이티브 코드가 함께 들어 있다.

VM 시작 시 코드 캐시는 설정된 값으로 최대 크기가 고정되므로 확장이 불가하다. 코드 캐시가 꽉 차면 그때부터 더 이상 JIT 컴파일은 안 되며, 컴파일되지 않은 코드는 인터프리터에서만 실행된다. 결국 최대로 낼 수 있는 성능에 한참 못 미치는 상태로 작동하게 된다.

코드 캐시는 미할당 영역과 프리 블록 연결 리스트를 담은 힙으로 구현된다. 네이티브 코드가 제거될 때마다 해당 블록이 프리 리스트에 추가된다. 블록 재활용은 스위퍼라는 프로세스가 담당한다. 

네이티브 메서드가 새로 저장되면 컴파일드 코드를 담기에 크기가 충분한 블록을 프리 리스트에서 찾아본다. 만약 그런 블록이 없으면 여유 공간이 충분한 코드 캐시 사정에 따라 미할당 공간에서 새 블록을 생성한다.

다음 경우, 네이티브 코드는 코드 캐시에서 제거된다.

- 역최적화될 때
- 다른 컴파일 버전으로 교체됐을 때
- 메서드를 지닌 클래스가 언로딩될 때

코드 캐시의 최대 크기는 다음 VM 스위치로 조정한다.

```java
-XX:ReservedCodeCacheSize=<n>
```

단계별 컴파일 기능을 켜면, c1 클라이언트 컴파일러의 낮아진 컴파일 한계치에 도달하는 메서드가 점점 늘어난다. 이를 감안해 디폴트 최대 크기값은 늘어난 컴파일드 메서드를 수용할 수 있게 더 커진다. 

**단편화**

C1 컴파일러를 거친 중간 단계의 컴파일드 코드가 C2 컴파일로 치환된 후 삭제되는 일이 잦아지면 코드 캐시는 단편화되기 쉽다. 결국 미할당 영역이 모두 소진되고 여유 공간은 전부 프리 리스트에 있는 것으로 나타나게 될 것이다.

새로 컴파일한 네이티브 코드를 담을 만한 큰 블록을 찾기 위해 코드 캐시 할당기는 연결 리스트를 샅샅이 뒤져야 할 것이다. 스위퍼 역시 프리 리스트로 재활용 가능한 블록을 찾느라 분주할 것이다. 결국 메모르 블록을 재배치하지 않는 가비지 수집 방식에서 단편화는 불가피하며 코드 캐시도 예외는 아니다. 압착을 하지 않으면 코드 캐시는 단편화되고 컴파일은 중단될 것이다. 캐시가 고갈되는 또 다른 형태일 뿐이다. 

### 간단한 JIT 튜닝법

단순 JIT 튜닝의 대원칙은 정말 간단하다. ‘컴파일을 원하는 메서드에게 아낌없이 리소스를 베풀라’ 라는 것이다. 이런 목표를 달성하려면 다음 항목을 점검해야 한다.

1. 먼저 PrintCompilation 스위치를 켜고 애플리케이션을 실행한다.
2. 어느 메서드가 컴파일됐는지 기록된 로그를 수집한다.
3. ReservedCodeCacheSize를 통해 코드 캐시를 늘린다.
4. 애플리케이션을 재실행한다.
5. 확장된 캐시에서 컴파일드 메서드를 살펴본다.

성능 엔지니어는 JIT 컴파일에 내재된 불확정성을 고려해야 한다. 이를 명심하면 두 가지 명백한 사실을 쉽게 관찰할 수 있다.

- 캐시 크기를 늘리면 컴파일드 메서드 규모가 유의미한 방향으로 커지는가?
- 주요 트랜잭션 경로상에 위치한 주요 메서드가 모두 컴파일되고 있는가?

캐시 크기를 늘려도 정작 컴파일드 메서드 개수는 그대로이고 로딩 패턴이 뚜렷하다면 JIT 컴파일러의 리소스가 부족한 게 아니다.

이때 트랜잭션이 몰리는 경로에 있는 메서드가 컴파일 로그에 전부 나타나는지 확인해야 한다. 그렇지 않다면 왜 이 메서드들이 컴파일되지 않았는지, 그 근본 원인을 찾아야 한다. 말하자면, 코드 캐시 공간이 모자라는 일이 없게 함으로써 JIT 컴파일이 절대 끊기지 않도록 보장하는 전략이다.