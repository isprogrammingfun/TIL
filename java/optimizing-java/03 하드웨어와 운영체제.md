## 하드웨어와 운영체제

### 메모리

무어의 법칙에 따라 개수가 급증한 트랜지스터는 처음엔 클록 속도를 높이는 데 쓰였다. 클록 속도가 증가하면 초당 더 많은 명령어를 처리할 수 있기 때문이다. 그러나 클록 속도가 증가하니 시간이 갈수록 프로세서 코어의 데이터 수요를 메인 메모리가 맞추기 어려워졌다. 

![image](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/cc4280f6-c523-4fa9-86df-71d33bfaf4a4)

- 메모리 캐시

위의 문제를 해결하기 위해 CPU 캐시가 고안되었다. CPU 캐시는 CPU에 있는 메모리 영역이다. 레지스터 보단 느리지만 메인 메모리 보다는 훨씬 빠르다. 자주 엑세스하는 메모리 위치는 CPU가 메인 메모리를 재참조하지 않게 사본을 떠서 CPU 캐시에 보관하자는 아이디어다. 

요즘 CPU는 엑세스 빈도가 높은 캐시일수록 프로세서 코어와 더 가까이 위치하는 식으로 여러 캐시 계층이 있다. CPU와 가장 가까운 캐시가 L1, 그 다음  캐시가 L2식으로 명명된다. 프로세서 아키텍처에 따라 캐시 개수 및 설정 상태는 제각각이지만, 일반적으로 각 실행 코어에 전용 프라이빗 캐시 L1,L2를 두고, 일부 또는 전체 코어가 공유하는 L3 캐시를 둔다. 

![image (1)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/408f1cb8-7c81-4301-a679-2b81e655394b)

CPU와 가까이 있는 캐시일수록 액세스 시간이 짧다. 이렇게 캐시 아키텍처를 이용해 액세스 시간을 줄이고 코어가 처리할 데이터를 계속 채워 넣는다. 클록 속도와 액세스 시간의 차이 때문에 최신 CPU는 더 많은 예산을 캐시에 투자한다. 

![image (2)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/759b2d3f-9415-47bf-8bd6-734f4b904bc2)


위에 사진은 완성된 설계도인데, CPU 코어마다 전용 L1, L2 캐시가 있고 모든 코어가 공유하는 L3 캐시가 있다. 메인 메모리는 노스브리지 컨포넌트를 거쳐 액세스하고 이 버스를 관통함으로써 메인 메모리 액세스 시간이 확 줄어든다. 

> 컴퓨터 아키텍처에서 "버스"는 데이터, 주소, 제어 신호 등을 전송하는 통신 경로를 나타낸다.
> 
> 
> 노스브리지는 CPU와 메인 메모리 사이의 통신을 담당하는 중요한 컨트롤러로, CPU에서 메인 메모리로 데이터를 전송하거나 반대로 메인 메모리에서 CPU로 데이터를 전송하는 데 사용되는 버스를 관통한다. 
> 
> 간단히 말해, "이 버스를 관통한다"는 의미는 노스브리지가 CPU와 메인 메모리 간의 통신에 개입하고 있다는 의미이다. 즉, CPU가 메모리 액세스를 요청할 때 노스브리지를 통해 데이터를 주고 받으며, 이를 통해 메인 메모리 액세스 시간이 개선되고 데이터 전송이 원활하게 이루어지는 것이다. 따라서 노스브리지가 중개하는 버스를 관통함으로써 데이터 전송과 컴퓨터의 성능이 향상되는 것이라고 볼 수 있다. 
> 

이렇게 캐시 아키텍처를 추가한 덕분에 프로세서 처리율은 현저히 개선됐지만, 메모리에 있는 데이터를 어떻게 캐시로 가져오고 캐시한 데이터를 어떻게 메모리에 다시 써야 할지 결정해야 했다. 이 문제는 캐시 일관성 프로토콜이라는 방법으로 해결한다. 프로세서의 가장 저수준에서 MESI 프로토콜이 자주 눈에 띄는데,  MESI 프로토콜은 캐시 라인 상태를 다음 네가지로 정의한다

1. Modified (M) 상태:
    - 캐시 라인이 "수정" 상태이며, 해당 데이터가 캐시에서 변경되었음을 나타낸다.
    - 캐시 라인이 M 상태인 경우, 해당 캐시는 해당 데이터의 독점적인 소유권을 가진다.
    - 다른 코어가 해당 데이터에 접근하려고 하면, 먼저 M 상태인 캐시가 데이터를 메모리로 기록하고, 캐시 라인은 Invalid 상태로 변경된다.
2. Exclusive (E) 상태:
    - 캐시 라인이 "독점" 상태이며, 해당 데이터를 한 캐시에서만 사용하고, 메모리와 동기화된 상태이다.
3. Shared (S) 상태:
    - 캐시 라인이 "공유" 상태이며, 해당 데이터가 여러 캐시에서 공유되고 있는 상태이다.
    - S 상태인 캐시 라인은 다른 코어가 해당 데이터를 읽을 수 있지만, 쓰기 접근은 허용되지 않는다.
    - 데이터가 변경되면, S 상태인 캐시 라인은 Invalid 상태로 변경된다.
4. Invalid (I) 상태:
    - 캐시 라인이 "무효" 상태이며, 해당 데이터가 캐시에 존재하지 않음을 나타낸다.
    - 데이터가 변경되거나 새로운 데이터가 캐시로 로드되면, 해당 캐시 라인은 Invalid 상태로 변경된다.
    
    MESI 프로토콜은 이러한 네 가지 상태를 관리하며, 캐시 라인의 상태 변화에 따라 다른 코어와의 데이터 동기화를 수행하여 캐시 일관성을 유지한다. 이를 통해 멀티프로세서 시스템에서 데이터의 정확성과 무결성을 보장하면서 성능을 향상시킬 수 있다. MESI 프로토콜은 현대적인 멀티코어 프로세서 시스템에서 널리 사용되는 일관성 프로토콜 중 하나로서, 캐시 일관성을 관리하는 데 있어서 효율적이고 신뢰성 있는 방법을 제공한다. 
    
    프로세스가 처음 나왔을 당시에는 매번 캐시 연산 결과를 바로 메모리에 기록했다. 이를 동시 기록이라고 하고, 메모리 대역폭을 너무 많이 소모하는 등 효율이 낮아 요즘 거의 안 쓴다. 나중에 출시된 프로세서는 후기록 방식을 채택하여 캐시 블록을 교체해도 프로세서가 변경된 캐시 블록만 메모리에 기록하므로 메인 메모리로 되돌아가는 트래픽이 뚝 떨어진다. 
    
    캐시 기술 덕에 데이터를 신속하게 메모리에서 쓰고 읽을 수 있게 되었다. 메모리 대역폭 측면에서 그 효과를 나타낼 수 있는데, 이론적으로 가능한 최대 전송률은 다음 인자에 따라 달라진다
    
    - 메모리 클록 주파수
    - 메모리 버스 폭 (보통 64비트)
    - 인터페이스 개수 (요즘 대부분 2개)
    
    ## 최신 프로세서의 특성
    
    ### 변환 색인 버퍼 (TLB)
    
    TLB는 여러 캐시에서 아주 긴요하게 쓰이는 장치이다. 가상 메모리 주소를 메모리 주소로 매핑하는 페이지 테이블의 캐시 역할을 수행한다. 덕분에 가상 주소를 참조해 물리 주소에 액세스하는 빈번한 작업 속도가 매우 빨라진다. 
    
    ### 분기 예측과 추측 실행
    
    분기 예측은 최신 프로세서의 고급 기법 중 하나로, 프로세서가 조건 분기하는 기준값을 평가하느라 대기하는 현상을 방지한다. 요즘 나온 프로세서는 다단계 명령 파이프라인을 이용해 CPU 1사이클도 각기 다른 실행 단계에서 여러 개별 단계로 나누어 실행하므로 여러 명령이 동시 실행 중일 수도 있다. 이런 모델에서는 조건문을 다 평가하기 전까지 분기 이후 다음 명령을 알 수 없는게 문제다. 그 결과, 분기문 뒤에 나오는 다단계 파이프라인을 비우는 동안 프로세서는 여러 사이클 동안 멎게 된다. 이런 일이 발생하지 않게 프로세서는 트랜지스터를 아낌없이 활용해 가장 발생 가능성이 큰 브랜치를 미리 결정하는 휴리스틱을 형성한다. 
    
    ### 하드웨어 메모리 모델
    
    “어떻게 하면 서로 다른 여러 CPU가 일관되게 동일한 메모리 주소를 액세스할 수 있을까?”는 멀티코어 시스템에서 메모리에 관한 가장 근본적인 질문이다. 
    
    이에 대한 답은 하드웨어에 따라 다르겠지만, JIT 컴파일러인 javac와 CPU는 일반적으로 코드 실행 순서를 바꿀 수 있다. 물론 이로 인해 현재 스레드가 바라보는 결과는 아무런 영향이 없다는 전제가 필요하다. 예를 들어 다음과 같은 코드가 있다.
    
    ```c
    myInt = otherInt;
    intChanged = true;
    ```
    
    두 할당문 사이에 다른 코드가 없기 때문에 실행 스레드 입장에선 이들이 어떤 순서로 오든 상관이 없다. 그렇기에 실행 환경에서는 명령 순서를 자유롭게 바꿀 수 있다. 그러나 이 변수들을 바라보는 다른 스레드 입장에서 실행 순서가 달라지면 intChanged는 true로 보여도 myInt는 옛날 값을 읽을 가능성이 있다. 
    
    JMM은 프로세서 타입별로 상이한 메모리 액세스 일관성을 고려해 명시적으로 약한 모델로 설계되었다. 따라서 멀티스레드 코드가 제대로 작동하게 하려면 락과 volatile을 정확히 알고 사용해야 한다. 
    
    ## 운영체제
    
    OS의 주 임무는 여러 실행 프로세스가 공유하는 리소스 액세스를 관장하는 일이다. 모든 리소스는 한정돼 있고 프로세스는 저마다 리소스를 더 차지하려고 하기 때문에 리소스 양을 보고 골고루 나누어 줄 중앙 시스템이 있어야 한다. 
    
    메모리 관리 유닛(MMU)을 통한 가상 주소 방식과 페이지 테이블은 메모리 액세스 제어의 핵심으로서, 한 프로세스가 소유한 메모리 영역을 다른 프로세스가 함부로 훼손하지 못하게 한다. 
    
    ### 스케줄러
    
    프로세스 스케줄러는 CPU 액세스를 통제한다. 이때 실행 큐(실행 대상이지만 CPU 차례를 기다려야 하는 스레드 혹은 프로세스 대기 장소)라는 큐를 이용한다. 최신 시스템은 거의 항상 가능한 수준보다 더 많은 스레드/프로세스로 가득하기 때문에 CPU 경합을 해소할 장치가 절실하다. 
    
    스케줄러는 인터럽트에 응답하고 CPU 액세스를 통제한다. 자바 명세서에는 이론적으로 자바 스레드가 굳이 OS 스레드와 일치할 필요 없는 스레딩 모델을 허용한다고 적혀있지만, 실제로 이런 방식이 유용하지 않다는 것을 알게 되고 주류 운영환경에서 배제되었다. 
    ![image (3)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/08eef81b-3e0e-40fa-8fa9-c1920d9222f1)
   
    위에 그림에서 스케줄러는 스레드를 시스템 단일 코어로 분주히 나른다. 스케줄러는 할당 시간 끝 무렵에 실행 큐로 스레드를 되돌려서 큐의 맨 앞으로가 다시 실행될 때까지 대기시킨다. 
    
    스레드가 자신이 할당받은 시간을 자발적으로 포기하려면 sleep() 메서드로 잠들 시간을 설정하거나 wait() 메서드로 대기 조건을 명시한다. 스레드는 I/O 또는 소프트웨어 락에 걸려 블로킹될 수도 있다. 
    
    OS는 특성상 CPU에서 코드가 실행되지 않는 시간을 유발한다. 쉽게 간과하기 쉬은 OS의 특징이다. 자신의 할당 시간을 다 쓴 프로세스는 실행 큐 맨 앞으로 갈 때까지 CPU로 복귀하지 않는다. CPU가 아껴 써야 할 리소스임을 감안하면 코드가 실행되는 시간보다 기다리는 시간이 더 많다는 것이다. 
    
    그렇기에 실제로 관측한 프로세스에서 나온 통계치는 시스템에 있는 다른 프로세스의 동작에도 영향을 받는다. 이런 지터와 스케줄링 오버헤드는 측정 결과에 노이즈를 끼게 만드는 주요인이다. 
    
    스케줄러의 움직임을 확인하는 가장 쉬운 방법은 OS가 스케줄링 과정에서 발생시킨 오버헤드를 관측하는 것이다. 
    
    ```java
    long start = System.currentTimeMillis();
    for(int i = 0; i < 1_000; i++) {
        Thread.sleep(1);
    }
    long end = System.currentTimeMillis();
    System.out.println("Millis elapsed: " + (end-start) / 4000.0);
    ```
    
    위에 코드는 1밀리초씩 총 1000회 스레드를 재운다. 스레드는 한번 잠들 때마다 실행 큐 맨 뒤로 가고 새로 시간을 할당받을 때까지 기다리므로 이 코드의 총 실행 시간을 보면 여느 프로세스에서 스케줄링 오버헤드가 얼마나 될지 짐작할 수 있다. 
    
    ### 시간 문제
    
    POSIX 같은 업계 표준이 있어도 OS는 저마다 다르게 작동한다. 
    
    ### 컨텍스트 교환
    
    컨텍스트 교환은 OS 스케줄러가 현재 실행 중인 스레드/태스크를 없애고 대기 중인 다른 스레드/태스크로 대체하는 프로세스이다. 컨텍스트 교환은 스레드 실행 명령과 스택 상태를 교체하는 모든 일에 연관되어 있다. 
    
    컨텍스트 교환은 비싼 작업이다. 특히 유저 모드에서 커널모드로 바뀌면서 일어나는 컨텍스트 교환이 비싸다. 왜냐하면 유저 공간에 있는 코드가 액세스하는 메모리 영역은 커널 코드와 거의 공유할 부분이 없기 때문에 모드가 바뀌면 명령어와 다른 캐시를 어쩔 수 없이 강제로 비워야 하기 때문이다. 
    
    커널모드로 컨택스트가 교환되면 TLB를 비롯한 다른 캐시까지도 무효화된다. 이들 캐시는 시스템 콜 반환 시 다시 채워야 하므로 커널 모드 교환의 여파는 유저 모드로 다시 제어권이 넘어간 후에서 당분간 이어진다. 
    
    ![image (4)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/b4214e0a-65ab-40f2-825e-aa6a94b32ecd)

    
    리눅스는 이를 최대한 만회하기 위해 가상 동적 공유 객체(vDSO)라는 장치를 제공한다. 이는 굳이 커널 프리빌리지가 필요 없는 시스템 콜의 속도를 높이려고 쓰는 유저 공간의 메모리 영역이다. 예를 들어보면 유닉스 시스템에서 아주 흔히 쓰이는 시스템 콜인 gettimeofday()는 물밑에서 커널 자료 구조를 읽어 시스템 클록 시간을 얻기 때문에 부수 효과를 일으키지 않으므로 실제로 프리빌리지드 액세스가 필요 없다. 이 자료 구조를 vDSO로 유저 프로세스의 주소 공간에 매핑시킬 수 있다면 커널 모드로 바꿀 필요가 없다. 
    
    ## 단순 시스템 모델
    
    단순한 시스템 모델을 통해 성능 문제를 일으키는 근원을 알아보다. 이 시스템 모델의 근본은 유닉스 계열 OS에서 작동하는 자바 애플리케이션의 단순한 개념으로 다음 기본 컴포넌트로 구성된다.
    
    - 애플리케이션이 실행되는 하드웨어와 OS
    - 애플리케이션이 실행되는 JVM/컨테이너
    - 애플리케이션 코드 자체
    - 애플리케이션이 호출하는 외부 시스템
    - 애플리케이션으로 유입되는 트래픽
    
   ![image (5)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/c0bf0059-0fab-4ad3-b776-9cbe345fec11)
    
    이들 중 누구라도 성능 문제를 일으킬 수 있다. 
    
    ## 기본 감지 전략
    
    애플리케이션이 잘 돌아간가는 건 CPU 사용량, 메모리, 네트워크, I/O 대역폭 등 시스템 리소스를 효율적으로 잘 이용하고 있다는 뜻이다. 
    
    성능 진단의 첫 단추는 어느 리소스가 한계에 다다랐는지 밝히는 일이다. 부족한 리소스가 뭔지 몰라서는 성능 지표를 제대로 튜닝할 수 없다. 
    
    그렇다고 OS 자체가 시스템을 가장 지치게 하는 원흉이 되어서도 안된다. OS의 임무는 유저 프로세스 대신 리소스를 관리하는 것이지, 자기 자신이 리소스를 소모하는 건 아니다. 
    
    ### CPU 사용률
    
    CPU 사용률은 애플리케이션 성능을 나타내는 핵심 지표이다. CPU 사이클은 애플리케이션이 가장 갈증을 느끼는 리소스라서 CPU의 효율적 사용은 성능 향상의 지름길이다. 또한 부하가 집중되는 도중에는 사용률이 가능한 100%에 가까워야 한다. 
    
    - vmstat
        
        유닉스 계열 OS 명령줄에 툴 명령어를 실행하면 각각 현재 가상 메모리 및 I/O 서브시스템 상태에 관한 유용한 데이터를 신속히 제공한다. 
        
        1. proc 섹션 : 실행 가능한(r) 프로세스, 블로킹된(b) 프로세스 개수를 나타낸다.
        2. memory 섹션 : 스왑 메모리(swpd), 미사용 메모리(free), 버퍼로 사용한 메모리(buff), 캐시로 사용한 메모리(cache)가 잇따라 표시된다.
        3. swap 섹션 : 디스크로 교체되어 들어간(스왑-인) 메모리(si), 디스크에서 교체되어 빠져나온 (스왑-아웃) 메모리(so) 정보
        4. io 섹션 : 블록-인(bi), 블록-아웃(bo) 개수는 각각 블록 (I/O) 장치에서 받은 512 바이트 블록, 블록 장치로 보낸 512 바이트 블록 개수이다
        5. system 섹션 : 인터럽트(in) 및 초당 컨텍스트 교환(cs) 횟수이다. 
        6. cpu 섹션: CPU와 직접 연관된 지표를 CPU 사용률로 표기한다. 좌측부터 차례로 유저 시간(us), 커널시간(sy, 시스템 타임) , 유휴시간(id), 대기 시간(wa), 도둑맞은 시간(st, 가상 머신에 할애된 시간)이다. 
        
        이를 기본툴이라고 무시하면 안된다. 이렇게 프로세스와 OS에 거의 맞닿아 단순한 툴은 시스템의 실제 작동 모습을 거의 그대로 드러낸다. 
        
    
    ### 가비지 수집
    
    핫스팟 JVM은 시작 시 메모리를 유저 공간에 할당/관리한다. 따라서 메모리를 할당하기 위해 시스템 콜을 할 필요가 없다. 즉, 가비지 수집을 하기 위해 커널 교환을 할 필요가 없다. 따라서 어떤 시스템에서 CPU 사용률이 아주 높게 나타난다면, GC는 대부분의 시간을 소비하는 주범이 아니다. GC 자체는 유저 공간의 CPU 사이클을 소비하되 커널 공간의 사용률에는 영향을 미치지 않는 활동이기 때문이다. 
    
    반면, 어떤 JVM 프로세스가 유저 공간에서 CPU를 100%에 가깝게 사용하고 있다면 GC를 의심해야 한다. 성능 분석 시 단순 툴에서 CPU 사용률이 100%로 일정하지만 모든 사이클이 유저 공간에서 소비되고 있으면 이렇게 CPU를 차지한 게 JVM인지 유저 코드일지 생각해봐야 한다. JVM에서 유저 공간의 CPU 사용률이 높은 이유는 대부분 GC 서브시스템 때문이다. 
    
    JVM에서 GC 로깅은 거의 공짜나 다름없다. GC 로깅은 분석용 데이터의 원천으로서도 가치가 높기 때문에 JVM 프로세스는 예외 없이, 특히 운영 환경에서는 GC 로그를 꼭 남겨야 한다. 
    
    ### 입출력
    
    파일 I/O는 예로부터 전체 시스템 성능에 암적인 존재였다. I/O는 다른 OS 파트처럼 분명하게 추상화되어 있지 않기 때문이다. 
    
    예를 들면 메모리 분야는 가상 메모리라는 격리 장치가 있지만, I/O는 그에 상응하여 애플리케이션 개발자가 적절히 추상화할 장치가 없다. 
    
    다행히도 자바 프로그램은 대부분 단순한 I/O만 처리하며 I/O 서브시스템을 심하게 가동하는 애플리케이션 클래스도 비교적 적은 편이고, CPU, 메모리 어느 한쪽과 I/O를 동시에 고갈시키는 애플리케이션은 거의 없다.  그뿐만 아니라 업무 체계가 잘 잡힌 운영 조직에서는 이미 I/O 한계를 잘 아는 담당 엔지니어가 I/O를 많이 쓰는 프로세스를 활발하게 모니터링하는 문화가 정착되어 있기 때문에 성능 분석자/엔지니어는 애플리케이션에서 I/O 가 어떻게 일어나는지 인지하는 것만으로도 충분하다. 
    
    - 커널 바이패스 I/O
        
        애플리케이션에 따라 달라지는 자바 애플리케이션 클래스에서 점점 더 많이 사용하는 또 다른 I/O이다. 
        
        커널 대신 직접 네트워크 카드에서 유저가 접근 가능한 영역으로 데이터를 매핑하는 전용 하드웨어/소프트웨어를 쓴다. 이렇게 하면 커널 공간과 유저 공간 사이를 넘나드는 행위 및 이중 복사를 막을 수 있다. 
        
    
    ### 기계 공감
    
    기계 공감은 성능을 조금이라도 쥐어짜내야 하는 상황에서 하드웨어를 폭넓게 이해하고 공감 할 수 있는 능력이 무엇보다 중요하다는 생각이다.
    
    기계 공감은 자바 개발자가 무시하기 쉬운 관심사이다. JVM이 하드웨어를 추상화했는데 굳이 개발자가 성능 관련 내용을 일일이 파악할 필요가 없기 때문이다. 그러나 고성능, 저지연이 필수인 분야에서 개발자가 자바/JVM을 효과적으로 활용하려면 JVM이란 무엇이고, 하드웨어와는 어떻게 상호작용하는지 이해해야 한다. 
    
    ## 가상화
    
    가상화는 다양한 종류가 있지만 이미 실행 중인 다른 OS 위에서 OS 사본을 하나의 프로세스로 실행시키는 모양새가 보통이다. 
    
    ![image (6)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/e08b47e7-5425-436e-8c8b-de09b95d792a)
    
    가상화의 특징은 다음 세 가지로 요약할 수 있다.
    
    - 가상화 OS에서 실행하는 프로그램은 베어 메탈(즉, 비가상화 OS)에서 실행할 때와 동일하게 작동해야 한다.
    - 하이퍼바이저는 모든 하드웨어 리소스 액세스를 조정해야 한다.
    - 가상화 오버헤드는 가급적 작아야 하며 실행 시간의 상당 부분을 차지해선 안 된다.
    
    일반 비가상화 시스템에서 OS 커널은 프리빌리지드 모드로 동작하므로 하드웨어를 직접 건드릴 수 있지만, 가상화 시스템에서는 게스트 OS가 하드웨어에 직접 액세스 할 수 없다. 
    
    따라서 대개 프리빌리지드 명령어를 언프리빌리지드(비특권) 명령어로 고쳐 쓴다. 또 컨텍스트 교환이 발생하는 동안 지나친 캐시 플러시가 일어나지 않도록 일부 OS 커널의 자료 구조는 섀도해야 한다. 
    
    ## JVM과 운영체제
    
    JVM은 자바 코드에 공용 인터페이스를 제공하여 OS에 독립적인 휴대용 실행 환경을 제공한다. 즉, 한 번 작성된 자바 코드는 여러 운영 체제에서 동일하게 실행될 수 있다. 하지만 스레드 스케줄링 같은 아주 기본적인 서비스는 하부 OS에 반드시 액세스해야 한다. 
    
    이런 기능은 NATIVE 키워드를 붙인 네이티브 메서드로 구현한다. 네이티브 메서드는 C언어로 작성하지만, 여느 자바 메서드 처럼 액세스할 수 있다. 이 작업을 대행하는 공통 인터페이스를 자바 네이티브 인터페이스(JNI)라고 합니다. 
    
    예를 들어 java.lang.Object 클래스에는 다음과 같이 논프라이빗 네이티브 메서드가 선언되어 있다.
    
    ```java
    public final native Class<?> getClass();
    public native int hashCode();
    protected native Object clone() throws CloneNotSupportedException;
    public final native void notify();
    public final native void notifyAll();
    public final native void wait(long timeout) throws InterruptedException;
    ```
    
    이들 메서드는 비교적 저수준의 플랫폼 관심사를 처리한다. 
    
    시스템 시간을 조회하는 예를 통해 자바 네이티브 인터페이스를 처리하는 흐름을 보자.
    
    ![image (7)](https://github.com/JSON-loading-and-unloading/Optimizing-Java/assets/78543382/25d0c1a9-215f-4eb0-b21a-797a5ef274ca)
    
    OS::javaTimeMillis() 함수는 자바 정적 메서드 System.currentTimeMillis()에 구현된 로직을 처리한다. 실제 코드는 C++로 작성됐지만 자바에서 C 코드 브리지를 통해 액세스할 수 있다. 핫스팟에서 이 코드는 실제로 어떻게 호출될까?
    
    네이티브 메서드 System.currentTimeMillis()는 JVM_CurrentTimeMillis()라는 JVM 엔트리 포인트 메서드에 매핑된다. JVM_CurrentTimeMillis()는 VM 진입점에 해당하는 메서드를 호출한다. 결국 OpenJDK 매크로 2개로 감싼 OS::javaTimeMillis()를 호출하는 구조이다.