## 동시 성능 기법

잘 만든 애플리케이션은 멀티코어에 부하를 고루 분산시켜 처리할 수 있다. 

이런 점에서 JVM 같은 애플리케이션 실행 플랫폼은 JIT 컴파일처럼 여러 프로세서 코어를 십분 활용할 수 있는 VM 스레드가 항상 떠 있기 때문에 장점이 뚜렷하다. 즉, 애플리케이션 스레드가 하나뿐이라도 멀티코어의 혜택을 누린다.

자바 개발자는 최신 하드웨어를 오롯이 활용하려면 자바 개발자는 최소한 동시성이 무엇인지, 애플리케이션 성능에 끼치는 영향을 무엇인지 최소한의 배경지식은 가지고 있어야 한다. 

### 병렬성이란?

멀티코어 세상에서는 암달의 법칙이 연산 태스크의 실행 속도를 향상 시키는 핵심 요소이다. 

암달의 법칙의 전체 태스크 소요 시간은 다음과 같다.

```
T(N) = S + (1/N) * (T-S)
// S : 순차 실행 파트 
// T : 총 캐스크 소요 시간 
// N : 프로세서 개수 
// T(N) : 프로세서 개수의 함수
// T - S : 동시 작업
```

수식을 보면, 프로세서 수를 무한히 늘려도 순차 작업 시간 이상 총 소요 시간을 줄일 수 없다. 즉, 순차 오버헤드가 전체의 5%라고 하면 아무리 코어를 늘려도 20배 이상 속도를 높이는 건 불가능하다. 

암달의 법칙에 다르면, 병렬 태스크나 다른 순차 태스크 간 소통의 필요가 전혀 없다면 이론적으론 속도를 무한히 높일 순 있다고 한다. (낯간지러운 병렬)

보통은 데이터 공유 없이 워크로드를 나누어 여러 스레드에 분산시킨다.

스레드끼리 상태나 데이터를 공유하기 시작하면 워크로드가 복잡해지고 일부 테스크는 순차 처리하게 되고, 통신 오버헤드가 발생한다.

> 정확한 프로그램을 작성하는 일은 어렵습니다. 정확한 동시 프로그램을 작성하는 건 훨씬 더 어렵습니다. 아무래도 순차 프로그래밍과 동시 프로그램이 잘못될 가능성이 더 크기 때문이죠.
> 

다시 말해, 상태를 공유하는 워크로드는 무조건 정교한 보호/제어 장치가 필요하다. 자바 플랫폼은 JVM에서 실행되는 워크로드에 JMM이라는 메모리 보증 세트를 제공한다. 

**자바 동시성 기초**

다음과 같이 카운터를 증가시키는 코드가 있다. 

```java
public class Counter {
    private int i = 0;

    public int increment() {
        return i = i + 1;
    }
}
```

바이트코드를 보면 값을 로드하고, 증가시키고, 저장하는 일련의 명령어가 있다.

카운터를 락으로 적절히 보호하지 않은 상태로 멀티스레드 환경에서 이 코드를 실행하면 다른 스레드가 저장하기 이전에 로드 작업이 일어날 가능성, 즉 다른 스레드가 수정한 결과가 소실될 수도 있다.

각 스레드는 메서드 개별 진입 시 각자 전용 평가 스택을 소유하므로 필드에 대한 작업은 서로 간섭이 일어날 수 있다. 왜냐하면 객체의 필드는 힙에 위치하고 모든 스레드가 함께 공유하기 때문이다. 

`volatile` 을 추가한다고 해서 안전하게 증분 연산을 할 수 있는 것은 아니다. 무조건 값을 캐시에서 다시 읽어들여 다른 스레드가 수정된 값을 바라보게 할 수는 있으나 증분 연산자의 복합적인 특성 탓에 방금 전 업데이트 소실 문제를 막을 수는 없다. 

`synchronized` 나 락으로 감싸지 않은 채 카운터가 무방비로 노출돼 있어서 프로그램을 돌릴 때 마다 두 스레드는 갖가지 형태로 서로 엮일 공산이 크다. 

대부분의 시간 동안 잘 실행되는 동시 프로그램과 정확히 작성된 동시 프로그램은 엄연히 다르다. 실패를 밝히는 건 정확함을 증명하는 것만큼이나 어려운 일이나, 실패 사례가 하나만 발견돼도 정확하지 않은 프로그램이라는 사실을 증명하고도 남는다.

그런데 동시 프로그램은 버그를 재연하기도 어렵다.

위에 문제는 `synchronized` 로 감싸서 `int` 같은 단순 값의 업데이트를 제어하면 해결할 수 있고, 자바 5 이전에는 이 방법이 유일했다. 

동기화를 사용할 땐 신중하게 설계하고 미리 잘 따져봐야 한다. `synchronized` 때문에 프로그램이 더 느려질 수도 있기 때문이다. 

처리율 향상은 동시성을 부여하는 전체 목표와 상충된다. 따라서 코드 베이스를 병렬화하는 작업을 진행할 때에는 복잡도가 늘어난 대가로 얻은 혜택을 충분히 입증할 수 있도록 성능 테스트가 수반되어야 한다. 

### JMM의 이해

자바에는 1.0 버전부터 공식적으로 `JMM` 이라는 메모리 모델이 있었다. 

JMM은 다음 질문에 답을 찾는 모델이다.

- 두 코어가 같은 데이터를 엑세스하면 어떻게 되는가?
- 언제 두 코어가 같은 데이터를 바라본다고 장담할 수 있는가?
- 메모리 캐시는 위 두 질문에 답에 어떤 영향을 미치는가?

자바 플랫폼은 공유 상태를 어디서 엑세스하든 JMM이 약속한 내용을 반드시 이행한다. 그 약속이란, 순서에 관한 보장과 여러 스레드에 대한 업데이트 가시성 보장, 두 가지로 분류된다. 

싱글코어에서 멀티코어로, 그리고 이제는 코어가 아주 많은 시스템으로 하드웨어가 발전하면서 메모리 모델의 본질 역시 점점 더 중요해졌다. 이제 순서와 스레드 가시성은 학문적 이론에 그치지 않고 실무 프로그래머가 작성한 코드에 직접적인 영향을 끼치는 실전적인 문제가 되었다. 

고수준에서 JMM 같은 메모리 모델은 두 가지 방식으로 접근한다.

- 강한 메모리 모델: 전체 코어가 항상 같은 값을 바라본다.
- 약한 메모리 모델: 코어마다 다른 값을 바라볼 수 있고 그 시점을 제어하는 특별한 캐시 규칙이 있다.

최신 멀티 CPU 시스템에서 강한 메모리 모델을 구현하면 사실상 메모리를 후기록(write-back)하는 것과 같다. 캐시 무효화 알림이 메모리 버스를 잠식하고 실제 메인 메모리 전송률은 급락할 것이다. 코어 수를 늘리는 건 상황을 악화시킬 뿐이라서 이런 방법은 근본적으로 멀티코어 체제에는 안 맞는다. 

또한 자바는 아키텍처에 독립적인 환경으로 설계된 플랫폼이므로 만약 JVM이 강한 메모리 모델 기반으로 설계됐다면, 네이티브 수준에서 강한 메모리 모델을 지원하지 않는 하드웨어에서 소프트웨어를 실행하기 위해서는 JVM에 별도 구현 작업이 필요하다. 

JMM은 아주 약한 메모리 모델이기에 실제 CPU 아키텍처 추세와 잘 어울린다. 또 JMM은 보장하는 내용이 거의 없어 이식 작업이 쉽다.

중요한 건 JMM이 최소한의 요건에 불과하다는 사실이다. 진짜 JVM 구현체와 CPU는 JMM 요건보다 하는 일이 훨씬 더 많다. 

JMM보다 강한 메모리 모델 기반의 하드웨어 플랫폼에서 개발한 애플리케이션은 동시성 버그를 갖고 있을 가능성이 있다. 하드웨어가 보장해주는 탓에 동시성 버그가 드러나지 않는다. 똑같은 애플리케이션을 약한 메모리 모델에 배포하면 하드웨어가 더 이상 보호해주지 못하므로 내재되어 있던 동시성 버그가 문제가 된다. 

JMM은 다음 기본개념을 기반으로 애플리케이션을 보호한다.

- Happens-Before: 한 이벤트는 무조건 다른 이벤트보다 먼저 발생한다.
- Synchronizes-With: 이벤트가 객체 뷰를 메인 메모리와 동기화시킨다.
- As-If-Serial: 실행 스레드 밖에서는 명령어가 순차 실행되는 것처럼 보인다.
- Release-Before-acquire: 한 스레드에 걸린 락을 다른 스레드가 그 락을 획득하기 전에 해제한다.

자바에서 스레드는 객체 상태 정보를 스스로 들고 다니며, 스레드가 변경한 내용은 메인 메모리로 곧장 반영되고 같은 데이터를 엑세스하는 다른 스레드가 반영된 데이터를 다시 읽는 구조이다. 

이런 맥락에서 볼 때 자바 `sychronized` 키워드가 나타내는 의미는 분명하다. `sychronized`는 ‘모니터를 장악한 스레드의 로컬 뷰가 메인 메모리와 동기화(Sychronizes-With)되었다.’라는 뜻이다. 

따라서 동기화 메서드, 동기화 블록은 스레드가 반드시 동기를 맞춰야할 접점에 해당하며, 다른 동기화 메서드/블록이 시작되기 전에 반드시 완료되어야 할 코드 블록을 정의해 놓은 것이다. 

JMM은 동기화되지 않은 엑세스에 대해선 동시성을 전혀 보장하지 않는다. 그런 보장이 필요하면 반드시 쓰기 액세스를 동기화 블록으로 감싸 캐시된 값을 메모리에 후기록해야 한다. 마찬가지로 읽기 엑세스도 동기화 코드 섹션 내부에 넣어 강제로 메모리를 다시 읽도록 해야 한다.

그러나 synchronized 락은 여러 한계점이 노출되었고, 시간이 지날수록 그 증상은 점점 더 심해진다. 

- 락에 걸린 객체에서 일어나는 동기화 작업은 모두 균등하게 취급된다. 따라서 쓰기 작업에만 `synchronized`를 적용하면 소실된 업데이트 현상이 나타난다. 읽기 작업에는 락을 걸 필요가 없을 것 같지만, 다른 스레드가 업데이트한 내용을 바라보게 하려면 반드시 synchronized를 사용해야 한다.
- 락 획득/해제는 반드시 메서드 수준이나 메서드 내부 동기화 블록 안에서 이루어져야 한다.
- 락을 얻지 못한 스레드는 블로킹된다. 락을 얻지 못할 경우, 락을 얻어 처리를 계속하려고 시도하는 것 조차 불가능하다.

## 동시성 라이브러리 구축

JMM은 성공적인 작품이긴 하지만 이해가 어렵고 실제로 응용하는 건 더 어렵다. 또한 인트린직 락킹의 제공하는 유연성이 떨어지는 것도 흠이다.

자바 5부터는 언어 수준에서 지원하는 기능에서 탈피해 고급 동시성 라이브러리와 툴을 자바 클래스 라이브러리의 일부로 표준화하려는 움직임이 확산되는 추세이다. 

`java.util.concurrent` 패키지는 멀티스레드 애플리케이션을 더 쉽게 개발할 수 있게 설계된 라이브러리다. 조건에 가장 잘 맞는 추상화 수준을 선택하는 일은 개발자의 몫이다. 추상화가 잘 된 `java.util.concurrent` 라이브러리를 골라 쓰면 ‘스레드 핫’ 성능도 함께 좋아진다. 이 라이브러리를 구성하는 핵심 요소는 몇 가지 일반 카테고리로 분류된다. 

- 락, 세마포어(semaphore)
- 아토믹스(atomics)
- 블로킹 큐
- 래치
- 실행자(executor)

일반적으로 라이브러리는 OS 품에서 벗어나 가급적 유저 공간에서 더 많은 일을 하려고 한다. 이렇게 하면 여러 가지로 장점이 있지만, 특히 라이브러리 로직이 유닉스 계열 OS 마다 존재하는 차이점 때문에 오락가락하지 않고 가급적 더 전역 범위에서 일관성을 보장한다는 측면에서 중요하다. 

락, 아토믹스 같은 일부 라이브러리는 CAS(compare and swap) 기법을 구현하기 위해 저수준 프로세서 명령어 및 OS 특성을 활용한다.

CAS는 에상되는 현재 값과 원하는 새 값, 그리고 메모리 위치(포인터)를 전달 받아 예상되는 현재 값을 메모리 위치의 콘텐츠와 비교한 후 일치하면 현재 값을 원하는 새 값으로 교체하는 아토믹 유닛이다. 

CAS는 여러 가지 중요한 고수준의 동시성 기능을 구성하는 기본 요소이다. 이 대목만 보더라도 JMM이 탄생한 이후 성능과 하드웨어 환경이 꾸준히 변경돼 왔음을 알 수 있다. 

최신 프로세서가 꽂힌 대부분의 하드웨어에 CAS 기능이 구현되어 있음에도 불구하고 JMM 또는 자바 플랫폼 명세서에는 CAS 이야기는 나오지 않는다. 사실 CAS는 구현체별 확장 기능이라고 볼 수 있으므로 CAS 하드웨어는 `sun.misc.Unsafe` 클래스를 통해 액세스한다. 

**Unsafe**

 `sun.misc.Unsafe` 는 내부 구현 클래스로 표준 자바 플랫폼 API가 아니다. 클래스명에 걸맞게 개발자가 직접 사용할 일은 거의 없다. 이 클래스를 사용하는 코드는 핫스팟 VM에 직접 연결되고 깨질 우려가 높다.

하지만, 어쩌다 보니 JVM의 표준 로직을 무너뜨리는 `Unsafe`는 거의 모든 주요 프레임워크의 구현 핵심부를 차지하게 됐다. 다음은 Unsafe로 할 수 있는 일들이다.

- 객체는 할당하지만 생성자는 아직 실행하지 않는다.
- 원메모리에 엑세스하고 포인터 수준의 연산을 수행
- 프로세서별 하드웨어 특성(CAS)를 이용한다.

덕분에 다음과 같은 고수준의 프레임워크 기능을 구현할 수 있다. 

- 신속한 (역)직렬화
- thread-safe한 네이티브 메모리 액세스
- 아토믹 메모리 연산
- 효율적인 객체/메모리 레이아웃
- 커스텀 메모리 펜스
- 네이티브 코드와의 신속한 상호작용
- JNI에 관한 다중 운영체제 대체물
- 배열 원소에 volatile하게 엑세스

Unsafe는 자바 SE 공식 표준은 아니지만, 워낙 업계에서 활용도가 높아 사실상 표준이나 다름없다. 또 비록 표준은 아니지만 필요한 특성을 담아주는 보관 창고로 쓰이게 되었다. 그러나 이런 것들은 자바 9부터 영향을 받게 됐고, 자바 버전 몇 개에 걸쳐 크게 변할 가능성이 크다.

**아토믹스와 CAS**

아토믹스는 값을 더하고 증감하는 복합 연산을 통해 get() 으로 계산한 결괏값을 돌려 받는다. 즉, 두 개별 스레드가 증분 연산을 하면 currentValue + 1과 currentValue + 2가 반환된다. 

아토믹 변수는 `volatile` 확장판이라고 할 수 있지만, 더 유연해서 상태 의존적 업데이트를 안전하게 수행할 수 있다. 

아토믹스는 자신이 감싸는 베이스 타입을 상속하지 않고 직접 대체하는 것도 허용되지 않는다. 예를 들어 `AtomicInteger`는 `Integer`를 상속한 클래스가 아니다. 사실 java.lang.Integer가 final 클래스라서 애당초 불가능하다. 

다음은 Unsafe로 단순 아토믹 호출을 구현하는 원리를 알 수 있는 코드이다. 

```java
public class AtomicIntegerExample extends Number {

    private volatile int value;

    // Unsafe.compareAndSwapInt로 업데이트하기 위해 설정
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    private static final long valueOffset;

    static {
        try {
            valueOffset = unsafe.objectFieldOffset(
                AtomicIntegerExample.class.getDeclaredField("value"));
        } catch (Exception ex) {
            throw new Error(ex);
        }
    }

    public final int get() {
        return value;
    }

    public final void set(int newValue) {
        value = newValue;
    }

    public final int getAndSet(int newValue) {
        return unsafe.getAndSetInt(this, valueOffset, newValue);
    }
    // 생략
}
```

Unsafe에 있는 메서드(getAndSetInt)를 사용했고, JVM을 호출하는 네이티브 코드가 핵심이다. 

```java
public final int getAndSetInt(Object o, long offset, int newValue) {
    int v;
    do {
        v = getIntVolatile(o, offset);
    } while (!compareAndSwapInt(o, offset, v, newValue));
    return v;
}

public native int getIntVolatile(Object o, long offset);

public final native boolean compareAndSwapInt(Object o, long offset,
                                              int expected, int x);
```

Unsafe 내부에서 루프를 이용해 CAS 작업을 반복적으로 재시도한다.

아토믹스를 효과적으로 활용하려면 주어진 기능 외에 임의로 코드를 구현해서 섞어 쓰지 말아야 한다. 가령 루프를 이용해 아토믹 증분 연산을 하는 코드는 이미 Unsafe에 그렇게 구현되어 있으니 필요가 없다. 

아토믹은 락-프리하므로 데드락은 있을 수 없다. 비교 후 업데이트하는 작업이 실패할 경우를 대비해 내부적인 재시도 루프가 동반된다. 대개 다른 스레드가 이제 막 업데이트를 할 때 그런일이 발생한다. 

변수를 업데이트하기 위해 여러 차례 재시도를 하면 횟수만큼 성능이 나빠진다. 성능을 고려할 때에는 처리율은 높은 수준으로 유지하기 위해 경합 수준을 잘 모니터링 해야 한다. 

**락과 스핀락**

인트린직 락은 유저 코드에서 OS를 호출함으로써 작동한다. OS 이용해 스레드가 신호를 줄 때까지 기다리기 만들기 때문에 막대한 오버헤드를 유발할 수 있다.

이를 개선하기 위해 나온 방법이 스핀락(spinlock)이다. 스핀락은 완전히 상호 베타적인 락보다 가볍게 쓸 수 있고, 블로킹된 스레드를 CPU에 활성 상태로 놔두고 아무 일도 시키지 않은 채 락을 얻을 때까지 ‘CPU를 태워가며’ 재시도하게 만드는 락이다. 최신 시스템은 대부분 하드웨어가 지원하리라 가정하고 CAS로 스핀락을 구현한다.

스핀락을 구현하는 코드는 CPU마다 다르겠지만 핵심 개념은 동일하다.

- ‘테스트하고 세팅’하는 작업은 반드시 아토믹해야 한다.
- 스핀락에 경합이 발생하면 대기 중인 프로세서는 tight loop를 실행하게 된다. (명령어는 별로 없는데 아주 많이 반복되는 루프)
- CAS는 예상한 값이 정확할 경우 한 명령어로 값을 안전하게 업데이트하며, 락 구성요소를 형성하는 데 한몫을 한다.

### 동시 라이브러리 정리

**java.until.concurrent 락**

락은 자바 5부터 전면 개편되어 좀 더 일반화한 락 인터페이스 `java.util.concurrent.locks.Lock` 에 추가되었다. 이 인터페이스를 이용하면 인트린직 락보다 더 많은 일을 할 수 있다. 

- `lock()`
    - 기존 방식처럼 락을 획득하고, 사용할 수 있을 때까지 블로킹한다.
- `newCondition()`
    - 락 주위에 조건을 설정해 더 유연하게 락을 활용하고, 락 내부에서 관심사를 분리할 수 있다. (읽기와 쓰기)
- `tryLock()`
    - 락을 획득하려고 시도한다. (타임아웃 옵션 설정 가능)
    - 스레드가 락을 사용할 수 없는 경우에도 계속 처리를 진행할 수 있다.
- `unlock()`
    - 락을 해제한다. `lock()`에 대응되는 후속 호출이다.

여러 종류의 락을 생성할 수 있고 여러 메서드에 걸쳐 락을 걸어놓는 것도 가능하다. 심지어 한 메서드에서는 락을 걸고 동시에 다른 메서드는 락을 해체할 수도 있다. 논블로킹 방식으로 락을 획득하려는 스레드는 `tryLock()` 메서드로 일단 시도해보고 락을 사용할 수 없을 경우 다시 물러나면 된다. 

ReentrantLock은 Lock의 주요 구현체로 내부적으로 int 값으로 `compareAndSwap()`을 한다. 즉, 경합이 없는 경우에는 락을 획득하는 과정이 락-프리하다. 그래서 락 경합이 별로 생기지 않는 시스템에선 성능이 매우 좋아지고 다양한 락킹 정책을 적용 가능한 유연성도 얻게 된다. 

실제로 `compareAndSwap()` 을 호출하고 Unsafe를 사용한 코드는 `AbstractQueuedSynchronizer` 를 확장한 정적 서브클래스 Sync에 있다. 또 `AbstractQueuedSynchronizer`는 스레드를 파킹 및 재개하는 메서드가 구현된 `LockSupport` 클래스를 활용한다.

 `LockSupport` 클래스는 스레드에게 퍼밋(허가증)을 발급한다. 발급할 퍼밋이 없으면 스레드는 기다려야 한다. 퍼밋을 발급하는 개념 자체는 세마포어와 비슷하지만, `LockSupport` 클래스는 오직 한 가시 퍼밋만 발급한다. 스레드는 퍼밋을 받지 못한 경우 잠시 파킹되었다가, 유효한 퍼밋을 받을 수 있을 때 다시 언파킹된다. 

**읽기/쓰기 락**

대부분 읽기와 쓰기 작업 횟수는 많이 차이가 난다. 왜냐하면 읽기는 상태를 바꾸지 않지만 쓰기는 상태를 바꾸기 때문이다. 기존 `synchronized`나 (조건 없는) `ReentrantLock`을 쓰면 한 가지 락 정책을 따를 수밖에 없다.

여러 읽기 스레드가 하나의 쓰기 스레드에 달려드는 상황에서는 어느 한 읽기 스레드로 인해 나머지 읽기 스레드가 불필요하게 블로킹되어 시간을 허비할 가능성이 있다.

이럴 때 `ReentrantReadWriteLock` 클래스의 `ReadLock` 과 `WriteLock` 을 활용하면 여러 읽기 스레드 작업 중 다른 읽기 스레드를 블로킹하지 않을 수 있다. 블로킹은 쓰기 작업을 할 때에만 일어난다. 

이런 락킹 패턴을 읽기 스레드가 매우 많을 경우에 적용하면 스레드 처리율이 크게 향상되고 락킹이 줄어든다. 락을 공정 모드로 세팅하면 성능은 떨어지지만 스레드를 반드시 순서대로 처리하게 할 수 있다. 

AgeCache 클래스를 다음 코드처럼 구현하면 단일 락을 사용했을 때보다 성능이 현저히 향상된다.

```java
public class AgeCache {

    private final ReentratReadWriteLock rwl = new ReentrantReadWriteLock();
    private final Lock readLock = rwl.readLock();
    private final Lock writeLock = rwl.writeLock();
    private Map<String, Integer> ageCache = new HashMap<>();

    public Integer getAge(String name) {
        readLock.lock();
        try {
            return ageCache.get(name);
        } finally {
            readLock.unLock();
        }
    }

    public void updateAge(String name, int newAge) {
        writeLock.lock();
        try {
            ageCache.put(name, newAge);
        } finally {
            writeLock.unLock();
        }
    }
}
```

**세마포어**

세마포어는 풀 스레드나 DB 커넥션 등 여러 리소스의 엑세스를 허용하는 독특한 기술을 제공한다. ‘최대 O개 객체까지만 엑세스를 허용한다.’ 는 전제하에 정해진 수량의 퍼밋으로 액세스를 제어한다. 

```java
// 퍼밋은 2개, 공정 모드로 설정된 세마포어 생성
private Semaphore poolPermits = new Semaphore(2, true);
```

`Semaphore` 클래스의 `acquire()` 메서드로 사용 가능한 퍼밋 수를 하나씩 줄인다. 더 이상 쓸 수 있는 퍼밋이 없을 경우 블로킹한다.

`release()` 메서드는 퍼밋을 반납하고 대기 중인 스레드 중 하나에게 해제한 퍼밋을 전달한다. 세마포어를 사용하면 리소스가 블로킹되거나 리소스를 기다리는 큐가 형성될 가능성이 커서 스레드 고갈을 막기 위해 처음부터 공정 모드로 초기화하는 경우가 많다. 

퍼밋이 하나뿐인 세마포어는 뮤텍스와 동등하다. 그러나 뮤텍스는 뮤텍스가 걸린 스레드만 해제할 수 있는 반면, 세마포어는 비소유 스레드도 해제할 수 있다는 점이 다르다. 이는 데드락을 강제로 해결해야 할 경우 필요한 방법이다. 

세마포어의 강점은 여러 퍼밋을 획득/해체할 수 있는 능력이다. 퍼밋을 여러 개 쓸 경우, 불공정 모드에선 스레드가 고갈될 가능성이 크기 때문에 공정 모드는 필수이다. 

**동시 컬렉션**

자바 5부터는 특별히 동시성을 고려해 설계된 컬렉션 인터페이스 구현체가 대거 등장했다. 자바 동시 컬렉션은 시간이 지나면서 스레드 핫 성능을 최고로 뽑아낼 수 있는 방향으로 조금씩 수정/보완돼 왔다. 

Map 구현체 (ConcurrentHashMap)는 버킷 또는 세그먼트로 분할된 구조를 최대한 활용하여 실질적인 성능 개션 효과를 얻는다. 각 세그먼트는 자체 락킹 정책, 즉 자신만의 락 세트를 가진다. 따라서 읽기/쓰기 락을 둘 다 소유한 상태에서 여러 읽기 스레드가 ConcurrentHashMap 곳곳을 읽는 동안, 쓰기가 필요할 경우 어느 한 세그먼트만 락을 거는 행위도 가능하다. 일반적으로 락을 걸지 않는 읽기 스레드는 안심하고 put()-, remove()- 작업을 중첩시켜도 되고, 완료된 업데이트 작업에 대해선 Happens-Before 순서대로 읽는다. 

이터레이터 (및 병렬 스트림용 스플릿터레이터)는 일종의 스냅샷으로 획득하기 때문에 에 `ConcurrentModiFicationException` 이 발생할 일은 없다는 사실이 중요하다. 충돌이 많을 경우 테이블이 동적으로 팽창하는데, 이런 작업은 비용이 많이 들기에 코드를 작성할 때 대략 예상가는 크기를 미리 지정하는 편이 좋다.

또 자바 5부터`CopyOnWriteArrayList`, `CopyOnWriteArraySet` 이 새로 도입돼서 어떤 사용 패턴에서는 멀티스레드 성능이 향상될 수 있다. 이 두 클래스에서 자료 구조를 변경하면 배킹 배열 사본이 하나 더 생성된다. 덕분에 기존 이터레이터는 예전 배열을 계속 탐색할 수 있고 레퍼런스가 하나도 없게 되면 이전 배열 사본은 GC 대상이 된다. 이렇게 스냅샷 스타일로 이터레이션 하므로 `ConcurrentModiFicationException` 이 발생하지 않는다.

이 방식은 카피-온-라이트 자료 구조를 변경하는 횟수보다 읽는 횟수가 월등히 많은 시스템에서 잘 작동한다. 시스템에 반영하기 전에 얼마나 성능 향상이 되는지 확실히 테스트를 수행한 후 결정해야한다. 

**래치와 배리어**

래치와 배리어는 스레드 세트의 실행을 제어하는 유용한 기법이다.

모든 스레드가 테스크#1 → 테스크#2 → 테스크#3 순서로 진행되는 것이 이상적이라면 래치를 쓰기 좋은 경우다.

```java
public class LatchExample implements Runnable {

    private final CountDownLatch latch;

    public LatchExample(CountDownLatch latch) {
        this.latch = latch;
    }

    @Override
    public void run() {
				//API 호출
        System.out.println(Thread.currentThread().getName() + "Done API Call");
        try {
            latch.countDown();
            latch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println(Thread.currentThread().getName() + " Continue processing");
    }

    public static void main(String[] args) throws InterruptedException {
        CountDownLatch apiLatch = new CountDownLatch(5);

        ExecutorService pool = Executors.newFixedThreadPool(5);
        for (int i = 0; i < 5; i++) {
            pool.submit(new CountdownLatchEx(apiLatch));
        }

        System.out.println(Thread.currentThread().getName() + " about to await on main");
        apiLatch.await();
        System.out.println(Thread.currentThread().getName() + " done awaiting on main");
        pool.shutdown();
        try {
            pool.awaitTermination(5, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            e.printStackTrace();
        }
        System.out.println("API Processing Complete");
    }
}
}
```

래치 카운트를 처음에 5로 세팅하고 각 스레드가 `countdown()`을 호출할 때마다 카운트 값이 1씩 감소한다.

카운트가 0이 되면 래치가 열리고 `await()` 함수 때문에 매여 있든 스레드가 해제되어 처리를 재개한다. 

이런 유형의 래치는 단 한번만 사용이 가능하다. 즉, 결과가 0이 되면 해당 래치는 두 번 다시 재사용할 수 없다. 리셋이란 개념이 아예 없다. 

방금 전 예제에서 래치를 두 가지 써서, 하나는 API 결과가 완료되는 시점에, 또 다른 하나는 DB 결과가 완료되는 시점에 적용하는 방법도 있다. 리셋이 가능한 CyclicBarrier를 사용하는 방법도 있지만, 어느 스레드가 리셋을 제어할지 판단하기가 제법 까다롭고 또 다른 종류의 동기화가 개입되어 복잡해진다. 파이프라인 각 단계마다 하나의 배리어/래치를 적용하는 것이 일반적인 베스트 프랙티스이다. 

### 실행자와 태스크 추상화

일반 자바 프로그래머는 저수준의 스레드 문제를 직접 처리하기 보단 `java.util.concurrent` 패키지에서 적절한 수준으로 추상화된 기능을 골라 쓰는 편이 좋다.

스레딩 문제가 거의 없는 추상화 수준은 동시 테스크로 기술할 수 있다. 즉, 현재 실행 컨텍스트 내에서 동시 실행해야 할 코드나 작업 단위로 기술할 수 있다. 일의 단위를 태스크로 바라보면 동시 프로그래밍을 단순화할 수 있다. 태스크를 실행하는 실제 스레드 수명 주기를 개발자가 일일이 신경 쓸 필요가 없기 때문이다. 

**비동기 실행이란?**

자바에서 태스크를 추상화하는 방법은, 값을 반환하는 태스크를 `Callable` 인터페이스로 나타내는 것이다. `Callable<V>` 은 `call()`  하나밖에 없는 제네릭 인터페이스로, call() 메서드는 V형 값을 반환하되 결괏값을 계산할 수 없으면 예외를 던진다.`Runnable` 과 비슷하나. `Runnable`은 결과값과 예외를 반환하지 않는다는 점에서 `Callable`과 다르다.

스레드가 살아 있는 동안 예외를 처리하는 일은 프로그래밍 세계의 난제 중 하나로, 정확히 관리하지 않으면 자바 프로그램이 엉뚱한 상태에 빠져버릴지도 모른다. 자바 스레드는 OS 수준 프로세스와 동등하며, 어떤 OS에서는 생성 비용이 비싼 경우도 있다. Runnable에서 결과를 가져오는 방식은 다른 스레드를 상대로 실행 반환을 조정해야 하기 때문에 복잡도가 가중될 수 있다.

`Callable<V>` 는 태스트를 추상화하는 수단을 제공한다. 그렇다면 태스크는 실제로 어떻게 실행되는 걸까?

`ExecutorService` 는 관리되는 스레드 풀에서 태스크 실행 메커니즘을 규정한 인터페이스이다. 풀에 담긴 스레드를 어떻게 관리하고 그 개수는 몇개까지 둘지는 이 인터페이스를 실제로 구현한 코드가 정의한다.  `ExecutorService` 는 submit() 메서드를 통해 Callable 객체를 받는다. 

`Executors` 는 헬퍼 클래스로, 선택한 로직에 따라 서비스 및 기반 스레드 풀을 생성하는 `new*` 팩토리 메서드 시리즈를 제공한다. 보통 이 팩토리 메서드로 실행자 메서드를 생성한다. 

- `newFixtedThreadPool(int nThreads)`
    - 크기가 고정된 스레드 풀을 지닌 `ExecutorService` 를 생성한다.
    - 풀 내부의 스레드는 재사용되며 여러 테스크를 실행한다.
    - 스레드가 전부 사용 중일 경우, 새 태스크는 큐에 보관한다.
- `newCachedThreadPool()`
    - 필요한 만큼 스레드를 생성하지만 가급적 스레드를 재사용하는 `ExecutorService`를 만든다.
    - 생성된 스레드는 60초간 유지되며 이후엔 캐시에서 삭제된다.
    - 소규모 비동기 태스크 성능을 향상시킬 수 있다.
- `newSingleThreadExecutor()`
    - 스레드 하나만 가동되는 `ExecutorService` 를 생성한다.
    - 새 태스크는 스레드를 이용할 수 있을 때까지 큐에서 대기한다.
    - 동시 실행 테스크 개수를 제한할 경우 유용하다.
- `newScheduledThreadPool(int corePoolSize)`
    - 미래 특정 시점에 태스크를 실행시킬 수 있도록 `Callable`과 지연 시간을 전달받는 메서드들이 있다.

**ExucatorService 선택하기**

올바른 `ExecutorService` 를 선택하면 비동기 프로세스를 잘 제어할 수 있고, 풀 스레드 개수를 정확히 잘 정하면 성능이 뚜렷이 향상될 수 있다. 

직접 ExecutorService를 작성하는 것도 가능하나, 그럴 일은 별로 없다. 커스터마이징하는 데 유용한 옵션은 사실 `ThreadFactory` 하나뿐이다. `ThreadFactory`를 이용하면  커스텀 스레드 생성기를 작성할 수 있다.

전체 애플리케이션 설정에 따라 ExecutorService를 경험적으로 튜닝해야 할 경우도 있다. 어떤 하드웨어에서 서비스가 실행 중인지, 어떤 리소스에서 경합이 벌어졌는지 파악하는 일이 전체 튜닝 그림을 그리는 데 매우 중요한 역할을 한다. 

가장 흔히 사용되는 지표는 코어 수 대비 풀 스레드 수이다. 동시 실행 스레드 개수를 프로세서 개수보다 높에 잡으면 경합이 발생하는 문제가 발생한다. OS가 스레드들을 실행 스케줄링해야 하는 부담을 안게 되어 결국 컨텍스트 교환이 더 자주 일어나게 된다. 

경합이 어느 한계치에 이르면 동시 처리 모드로 전환하더라도 성능 효과는 반감될 수 있더. 그래서 성능 모델을 올바르게 정립하고 성능 향상 정도를 측정할 수 있는 역량을 갖추는 일이 시급하다. 

**포크/조인**

자바는 개발자가 손수 스레드를 제어/관리하지 않아도 되도록 다양한 방식으로 동시성 문제를 처리한다. 자바 7부터 등장한 포크/조인 프레임워크는 멀티 프로세서 환경에서 효율적으로 작동하는 새로는 API를 제공한다. 이 프레임워크는 `ForkJoinPool`라는 새로운 `ExecutorService` 구현체에 기반한다. 

`ForkJoinPool` 클래스는 관리되는 스레드 풀을 제공하며, 다음과 같은 두 가지 특성이 있다. 

- 하위 분할 테스크(subdivided task)를 효율적으로 처리 가능
- 작업 빼앗기(work-stealing) 알고리즘을 구현

하위 분할 테스크는 표준 자바 스레드보다 가벼운, 스레드와 비슷한 엔티티로 `ForkJoinTask` 클래스가 지원하는 기능이다. `ForkJoinPool` 실행자에서 적은 수의 실제 스레드가 아주 많은 태스크/서브태스크를 담당해야 하는 유스케이스에 주로 사용한다.

`ForkJoinTask` 의 핵심은 자신을 더 작은 서브태스크로 분할하는 능력이다. 직접 계산하기에 충분할 정도까지 잘게 태스크를 나눈다. 그래서 이 프레임워크는 순수 함수 계산이나 다른 ‘낯간지러운 병렬’ 작업처럼 특정 부류의 작업에 한하여 잘 맞는다. 잘 맞는 경우에도 포크/조인 파트를 완전히 활용하려면 알고리즘이나 코드 재작성이 필요할 수도 있다. 

그러나 작업 빼앗기 알고리즘은 태스크 하위 분할과 독립적으로 응용할 수 있다. 예를 들어, 어느 스레드가 자신이 할당받은 작업을 모두 마쳤는데 다른 스레드에 아직 백로그(큐에 쌓인 작업들)가 남아 있으면 바쁜 스레드 큐에서 작업을 몰래 가져와 실행할 수 있다.

`ForkJoinPool`에 있는 `commonPool()` 정적 메서드로 전체 시스템 풀의 레퍼런스를 반환한다. 덕분에 개발자가 직접 자체 풀을 생성해 공유할 필요가 없고, 공용 풀은 지연 초기화되므로 필요한 시점에 생성된다.

풀 크기는 `Runtime.getRuntime().availableProcessors() - 1`로 정해지지만 항상 기대한 결괏값을 반환하지는 않는다.

### 최신 자바 동시성

원래 자바 동시성은 실행 시간이 긴 블로킹 태스크를 다른 스레드와 함께 실행할 수 있게 인터리빙하는 환경을 염두에 두고 설계되었다. 오늘날에는 사실 개발자가 코드를 작성하는 모든 대상 머신이 여러 프로세서가 달린 시스템이다 보니 가용한 CPU 리소스를 효율적으로 사용하는 문제가 더욱 중요하게 부각되었다. 

자바는 언어 수준에서 스레딩을 지원한, 업계 최고의 표준 환경이었고, 개발자들의 다양한 경험을 통해 스레드는 현대 애플리케이션 개발에 있어 훨씬 더 저수준으로 추상화한 산물이 되었다. 그리고 현대 자바는 표준 라이브러리에 내장된 추상화를 이용해 성능을 높일 수 있는 환경을 제공한다.

**스트림과 병렬 스트림**

자바 8의 가장 큰 변경 사항은 람다와 스트림이다. 람다/스트림을 함께 사용하면 자바 개발자도 함수형 프로그래밍의 혜택을 누릴 수 있게 되었다. 

자바 스트림은 데이터 소스에서 원소를 퍼 나르는 불변 데이터 시퀸스로, 모든 타입의 데이터 소스(컬렉션, I/O)에서 추출할 수 있다. 스트림은 람다 표현식, 또는 데이터를 가공하는 함수 객체를 받는 map() 같은 함수를 교묘히 잘 활용한다. 기존 루프를 내부 이터레이션(스트림)으로 변형했기 때문에 데이터를 병렬화하거나 복잡한 표현식의 평가를 지연시킬 수도 있다.

모든 컬렉션은 `Collection` 인터페이스의 `stream()` 메서드를 제공한다. `stream()` 은 컬랙션에서 스트림을 생성하는 구현체를 내어주는 디폴트 메서드로, 내부에서 `ReferencePipeline`을 생성한다.

`parallelStream()`을 이용하면 병렬로 데이터를 작업 후 결과를 재조립할 수 있다. 이 메서드를 호출하면 내부적으로 `Spliterator`를 써서 작업을 분할하고 공용 포크/조인 풀에서 연산을 수행한다. 이는 까다로운 병렬 문제를 다룰 때 편리하다. 스트림은 원래 처음부터 불변이므로 병렬 실행하더라도 상태 변경으로 생기는 문제를 예방할 수 있다. 

스트림 도입은 `RecursiveAction` 으로 기록하는 것 보다 더 친숙한 구문으로 포크/조인을 다룰 수 있는 길을 열었다. 문제를 데이터 관점으로 표현하는 건, 개발자가 저수준의 스레드 역학 및 데이터 변경 문제를 신경 쓰지 않을 수 있게 도와주는 일종으 태스크 추상화이다. 

`parallelStream()`을 사용하고 싶은 경우, 여느 병렬 연산처럼 태스크를 찢어 여러 스레드에 분배하고 그 결과를 다시 취합하는 일은 피할 수 없기 때문에 이에 따른 대가는 감수해야 한다. 

**락-프리 기법**

락-프리 기법은 블로킹이 처리율에 악영향을 미치고 성능을 저하시킬 수 있다는 전제하에 시작한다. 블로킹의 문제점은, 스레드를 컨텍스트 교환할 기회가 있다는 사실을 OS에 의지해 나타낸다는 점이다. 또한 중단/재개시키는 과정에서 많은 시간이 소요될 수 있기에 락-프리한 기법보다 훨씬 느리다.

락-프리 기법 역시 대가는 따른다. CPU 코어를 차지하면서 사용률, 전력 소비 측면에서 비용이 든다.

**액터 기반 기법**

액터는 그 자체로 고유한 상태와 로직을 갖는다. 동시에 다른 액터와 소통하는 메일박스 체계를 갖춘 작고 독립적인 처리 단위이다. 액터는 가변적인 상태는 일체 공유하지 않고 불변 메시지를 통해서만 상호 통신함으로써 상태를 관리한다. 액터 간 통신은 비동기적이며 메시지 수신에 반응하여 정해진 일을 한다.

액터는 병렬 시스템 내부에서 하나의 네트워크를 생성하고 각자 작업을 수행함으로써 하부 동시 모델을 완전히 추상화한다.

액터는 동일한 프로세스 내부에서 존재하지만 꼭 그래야 한다는 법은 없기에 다중처리가 가능하고, 심지어 멀티 머신에 걸쳐 있는 상태로도 작동이 가능하다.

액터 기반 시스템은 멀티 머신과 클러스터링 덕분에 어느 정도 내고장성이 필요한 상황에서 효과적으로 작동한다. 협동 체제에서 액터를 제대로 작동시키기 위해 실패할 가능성이 조금이라도 있는 상황 및 조건을 즉시 보고하는 방식인 페일-패스트 전략을 구한다. 

JVM 계열 언어에선 스칼라 언어로 작성되었고, 자바 API도 제공하는 아카(Akka) 프레임워크가 널리 알려져있다. 아카와 액터 기반 시스템의 주목적은 동시 프로그래밍을 곤란하게 만드는 제반 문제들을 해결하는 것이다. 전통적 락킹보다 아카를 쓰는 것이 더 좋은 3가지 이유는 다음과 같다. 

- 도메인 모델 내의 가변 상태를 캡슐화하는 것은 까다로운 일이다. 특히, 객체 내부 요소를 가리키는 레퍼런스가 언제든 제어권 밖으로 벗어날 수 있기 때문에 더욱 그렇다.
- 상태를 락으로 보호하면 처리율이 크게 떨어질 수 있다.
- 락을 쓰면 데드락을 비롯한 별별 문제가 유발된다.

이 밖에 공유 메모리를 정확히 사용하기 어려운 점, CPU 캐시 라인을 공유하게 함으로 발생할 수도 있는 성능 문제도 있다.

액터 모델이 대체로 동시성 애플리케이션 개발자에게 유용한 툴이긴 하지만, 그렇다고 다른 기법 전체를 대체할 수 있는 범용 툴은 아니다. 액터 방식(불변 메시지의 비동기 전송, 가변 상태 공유 금지, 각 메시지가 제한된 시간 동안 실행)이 잘 맞는 유스케이스에서는 최상이겠지만, 설계 요건상 요청-응답의 비동기 처리, 가변 상태 공유, 무제한 실행 등을 고려해야 한다면 다른 방법을 찾는 것이 좋다.